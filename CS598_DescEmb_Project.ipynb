{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "12eeb976-aec8-4203-979f-ed85033f9aa9",
      "metadata": {
        "id": "12eeb976-aec8-4203-979f-ed85033f9aa9"
      },
      "source": [
        "# CS598 Project: Enhancing Healthcare Predictive Models through Text-Based EHR Code Embedding\n",
        "\n",
        "**Name:** Gene Horecka  \n",
        "**Email:** [geneeh2@illinois.edu](mailto:geneeh2@illinois.edu)  \n",
        "**Course:** CS 598 Deep Learning for Healthcare - Spring 2024\n",
        "## Project Github Link: [https://github.com/genefever/cs598_descemb_project](https://github.com/genefever/cs598_descemb_project)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2sNScl0mbzOU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sNScl0mbzOU",
        "outputId": "c922d60e-51a3-4f05-c48b-6c6a2ce6c24a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3sayE7uHdFCZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sayE7uHdFCZ",
        "outputId": "b4693fc7-1d4b-4300-d43c-ca1d67a9ca89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 5 (delta 3), reused 5 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects:  20% (1/5)\rUnpacking objects:  40% (2/5)\rUnpacking objects:  60% (3/5)\rUnpacking objects:  80% (4/5)\rUnpacking objects: 100% (5/5)\rUnpacking objects: 100% (5/5), 595 bytes | 297.00 KiB/s, done.\n",
            "From https://github.com/genefever/cs598_descemb_project\n",
            "   4933420..0c92977  gpu        -> origin/gpu\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "vt-IWJ9tJ86I",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt-IWJ9tJ86I",
        "outputId": "63ad8273-64eb-433c-d3a2-918ec264cb43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'cs598_descemb_project'...\n",
            "remote: Enumerating objects: 307, done.\u001b[K\n",
            "remote: Counting objects: 100% (307/307), done.\u001b[K\n",
            "remote: Compressing objects: 100% (157/157), done.\u001b[K\n",
            "remote: Total 307 (delta 146), reused 282 (delta 122), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (307/307), 16.29 MiB | 12.10 MiB/s, done.\n",
            "Resolving deltas: 100% (146/146), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/genefever/cs598_descemb_project.git\n",
        "!cd cs598_descemb_project\n",
        "!git checkout gpu\n",
        "!git branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "u-2RNfLlLI93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-2RNfLlLI93",
        "outputId": "ef2f2dde-4ffe-42ed-d60c-b8fb83e32cbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Working Directory:  /content/cs598_descemb_project\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "os.chdir('/content/cs598_descemb_project')\n",
        "print(\"Current Working Directory: \", os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c719c0ca",
      "metadata": {
        "id": "c719c0ca"
      },
      "source": [
        "\n",
        "# Introduction\n",
        "\n",
        "The paper \"[Unifying Heterogeneous Electronic Health Records Systems via Text-Based Code Embedding](https://arxiv.org/abs/2108.03625)\" addresses the significant challenge of heterogeneity in Electronic Health Records (EHR) systems. These systems, essential for modern healthcare, often differ in their coding and formatting of medical data, which hampers the development and application of predictive models across different institutions or datasets.\n",
        "\n",
        "The primary contribution of this paper is the development of a novel framework named [Description-based Embedding (DescEmb)](https://github.com/hoon9405/DescEmb). This framework uses neural language models to create a unified, code-agnostic text-based representation of medical data. By transforming various coding formats into a consistent text-based embedding, DescEmb allows for more flexible and effective application of deep learning models across diverse EHR systems. This approach notably enhances the performance of predictive healthcare models, demonstrating superior results in several experimental setups compared to traditional code-based embedding methods."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f64856b9",
      "metadata": {
        "id": "f64856b9"
      },
      "source": [
        "\n",
        "# Scope of Reproducibility\n",
        "\n",
        "The scope of reproducibility for the paper \"[Unifying Heterogeneous Electronic Health Records Systems via Text-Based Code Embedding](https://arxiv.org/abs/2108.03625)\" entails verifying the claims of improved predictive performance through the implementation of the DescEmb framework. This framework leverages a neural language model to convert medical codes into a unified, text-based embedding, which is purported to enhance predictive healthcare research without the constraints imposed by diverse EHR systems.\n",
        "\n",
        "## Key Claims for Reproduction:\n",
        "1. **Unified Learning Across Diverse EHR Formats:** DescEmb can unify learning across various EHR systems without needing individualized pre-processing or domain-specific knowledge, due to its text-based nature.\n",
        "2. **Superior Predictive Performance:** The framework demonstrates better or comparable predictive performance than traditional code-based approaches across several clinical prediction tasks.\n",
        "3. **Efficient Deployment in Diverse Environments:** The text-based approach allows models trained with DescEmb to be easily transferred and applied across different hospitals with differing EHR systems.\n",
        "\n",
        "The reproducibility effort will focus on these claims by attempting to replicate the experiments outlined in the original paper using the datasets and code provided in the project's [GitHub repository](https://github.com/hoon9405/DescEmb). The process will involve re-running the model training and evaluation procedures to verify the reported performance improvements and the operational flexibility of the DescEmb approach.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "959ee017-b71e-4406-ba6a-ff4abe8fc620",
      "metadata": {
        "id": "959ee017-b71e-4406-ba6a-ff4abe8fc620"
      },
      "source": [
        "# Methodology\n",
        "\n",
        "## Requirements\n",
        "\n",
        "- PyTorch version >= 1.8.1\n",
        "- Python version >= 3.7\n",
        "\n",
        "## Setting Up the Environment\n",
        "\n",
        "To replicate the preprocessing and modeling described in the project, the following environment must be set up:\n",
        "\n",
        "1. **Conda Environment**: Use the provided `environment.yml` file to create a Conda environment. This will install all required dependencies, including Python and PyTorch. Run the following command in your terminal:\n",
        "\n",
        "   ```bash\n",
        "   conda env create -f environment.yml\n",
        "\n",
        "\n",
        "\n",
        "2. **Activate the Environment**\n",
        "\n",
        "   ```bash\n",
        "   conda activate descemb\n",
        "\n",
        "## Data\n",
        "\n",
        "### Data Description\n",
        "\n",
        "The datasets used in this project are MIMIC-III and eICU, which are publicly available on the PhysioNet repository. These datasets include comprehensive data from intensive care units (ICUs), such as time-stamped records of medical events, lab results, medications, and more, recorded in different medical code systems.\n",
        "\n",
        "- [**MIMIC-III**](https://physionet.org/content/iii/1.4/): Contains data for over 60,000 ICU stays at Beth Israel Deaconess Medical Center between 2001 and 2012. It includes information such as lab measurements, medication orders, and diagnostic codes.\n",
        "- [**eICU**](https://physionet.org/content/eicu-crd/2.0/): A multi-center dataset containing data for over 200,000 ICU stays across the United States between 2014 and 2015. It includes similar types of data to MIMIC-III but is structured differently.\n",
        "- [**ccs_multi_dx_tool_2015**](https://www.hcup-us.ahrq.gov/toolssoftware/ccs/Multi_Level_CCS_2015.zip): The Clinical Classifications Software (CCS) 2015 dataset groups ICD-9-CM diagnosis and procedure codes into clinically meaningful categories that are useful for health data analysis and research.\n",
        "- [**icd10cmtoicd9gem**](https://data.nber.org/gem/icd10cmtoicd9gem.csv): The `icd10cmtoicd9gem.csv` file is a mapping table that converts ICD-10-CM codes to ICD-9-CM codes.\n",
        "\n",
        "### Data Access\n",
        "\n",
        "The datasets utilized in this project, MIMIC-III and eICU, are publicly available via PhysioNet. Users must adhere to licensing agreements and data usage policies, including the requirement for completing a training course on data handling. Detailed instructions for data access are as follows:\n",
        "\n",
        "- **MIMIC-III** and **eICU**: Access these datasets by registering and completing the required data usage agreement at [PhysioNet](https://physionet.org/). After gaining access, download the data directly from their respective project pages.\n",
        "\n",
        "- Alternatively, you can use the public [**MIMIC-III Demo Dataset**](https://physionet.org/content/mimiciii-demo/1.4/) and [**eICU Demo Dataset**](https://www.physionet.org/content/eicu-crd-demo/2.0.1/) without having to create an account, albeit it will just be a fraction of the real dataset. However, this is a good option if you would like to get started quickly and run the computations on a CPU.\n",
        "\n",
        "### Data Preparation\n",
        "\n",
        "The preparation of the datasets for training involves several steps, from downloading the data to preprocessing it into a usable format. Here’s how you can prepare your data:\n",
        "\n",
        "1. **Download the Data**: After obtaining the necessary permissions, download the datasets from PhysioNet.\n",
        "2. **Organize the Data**: Arrange the downloaded files according to the directory structure below:\n",
        "```\n",
        "data_input_path\n",
        "├─ mimic\n",
        "│  ├─ ADMISSIONS.csv\n",
        "│  ├─ PATIENTS.csv\n",
        "│  ├─ ICUSYAYS.csv\n",
        "│  ├─ LABEVENTES.csv\n",
        "│  ├─ PRESCRIPTIONS.csv\n",
        "│  ├─ PROCEDURES.csv\n",
        "│  ├─ INPUTEVENTS_CV.csv\n",
        "│  ├─ INPUTEVENTS_MV.csv\n",
        "│  ├─ D_ITEMDS.csv\n",
        "│  ├─ D_ICD_PROCEDURES.csv\n",
        "│  └─ D_LABITEMBS.csv\n",
        "├─ eicu\n",
        "│  ├─ diagnosis.csv\n",
        "│  ├─ infusionDrug.csv\n",
        "│  ├─ lab.csv\n",
        "│  ├─ medication.csv\n",
        "│  └─ patient.csv\n",
        "├─ ccs_multi_dx_tool_2015.csv\n",
        "└─ icd10cmtoicd9gem.csv\n",
        "\n",
        "```\n",
        "```\n",
        "data_output_path\n",
        "├─mimic\n",
        "├─eicu\n",
        "├─pooled\n",
        "├─label\n",
        "└─fold\n",
        "```\n",
        "\n",
        "3. **Preprocess the Data**: Use the following Python script to execute the preprocessing steps. This script automates the process of converting raw datasets into a format ready for model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "X3xuW6auMfFJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3xuW6auMfFJ",
        "outputId": "36384870-acc5-4f19-a240-f095afad25c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting iterative-stratification\n",
            "  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from iterative-stratification) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from iterative-stratification) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from iterative-stratification) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->iterative-stratification) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->iterative-stratification) (3.5.0)\n",
            "Installing collected packages: iterative-stratification\n",
            "Successfully installed iterative-stratification-0.1.7\n"
          ]
        }
      ],
      "source": [
        "!pip install iterative-stratification tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "29c46dd8-9da6-4e25-aace-9ef771cf6a2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29c46dd8-9da6-4e25-aace-9ef771cf6a2a",
        "outputId": "1b52413c-c6a3-49d9-bf46-5ad021c112b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "working directory .. :  /content/cs598_descemb_project\n",
            "Destination directory is set to datasets/data_output_path\n",
            "Data directory is set to datasets/data_input_path/eicu\n",
            "eicu_cohort.pkl already exists skip create cohort step!___\n",
            "eicu_df.pkl already exists skip dataframe generation step!___\n",
            "label numpy file save to  datasets/data_output_path/eicu/label/mortality.npy\n",
            "label numpy file save to  datasets/data_output_path/eicu/label/readmission.npy\n",
            "label numpy file save to  datasets/data_output_path/eicu/label/los_3day.npy\n",
            "label numpy file save to  datasets/data_output_path/eicu/label/los_7day.npy\n",
            "['1' '10' '12' '16' '17' '18' '2' '3' '4' '5' '6' '7' '8' '9']\n",
            "label numpy file save to  datasets/data_output_path/eicu/label/diagnosis.npy\n",
            "seed :  1\n",
            "mortality train and test split\n",
            "X fold_task value counts \n",
            " mortality_fold\n",
            "1    101\n",
            "Name: count, dtype: int64\n",
            "\n",
            "1 label distribution:\n",
            "mortality\n",
            "0    0.957746\n",
            "1    0.042254\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "2 label distribution:\n",
            "mortality\n",
            "0    1.0\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "0 label distribution:\n",
            "mortality\n",
            "0    0.9\n",
            "1    0.1\n",
            "Name: proportion, dtype: float64\n",
            "fold split eicu with mortality done \n",
            " mortality_fold\n",
            "1    71\n",
            "2    20\n",
            "0    10\n",
            "Name: count, dtype: int64\n",
            "readmission train and test split\n",
            "X fold_task value counts \n",
            " readmission_fold\n",
            "1    101\n",
            "Name: count, dtype: int64\n",
            "\n",
            "1 label distribution:\n",
            "readmission\n",
            "0    0.876923\n",
            "1    0.123077\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "2 label distribution:\n",
            "readmission\n",
            "0    0.8\n",
            "1    0.2\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "0 label distribution:\n",
            "readmission\n",
            "0    0.9375\n",
            "1    0.0625\n",
            "Name: proportion, dtype: float64\n",
            "fold split eicu with readmission done \n",
            " readmission_fold\n",
            "1    65\n",
            "2    20\n",
            "0    16\n",
            "Name: count, dtype: int64\n",
            "los_3day train and test split\n",
            "X fold_task value counts \n",
            " los_3day_fold\n",
            "1    101\n",
            "Name: count, dtype: int64\n",
            "\n",
            "2 label distribution:\n",
            "los_3day\n",
            "0    0.55\n",
            "1    0.45\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "0 label distribution:\n",
            "los_3day\n",
            "0    0.692308\n",
            "1    0.307692\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "1 label distribution:\n",
            "los_3day\n",
            "0    0.705882\n",
            "1    0.294118\n",
            "Name: proportion, dtype: float64\n",
            "fold split eicu with los_3day done \n",
            " los_3day_fold\n",
            "1    68\n",
            "2    20\n",
            "0    13\n",
            "Name: count, dtype: int64\n",
            "los_7day train and test split\n",
            "X fold_task value counts \n",
            " los_7day_fold\n",
            "1    101\n",
            "Name: count, dtype: int64\n",
            "\n",
            "1 label distribution:\n",
            "los_7day\n",
            "0    0.926471\n",
            "1    0.073529\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "2 label distribution:\n",
            "los_7day\n",
            "0    0.95\n",
            "1    0.05\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "0 label distribution:\n",
            "los_7day\n",
            "0    0.923077\n",
            "1    0.076923\n",
            "Name: proportion, dtype: float64\n",
            "fold split eicu with los_7day done \n",
            " los_7day_fold\n",
            "1    68\n",
            "2    20\n",
            "0    13\n",
            "Name: count, dtype: int64\n",
            "diagnosis multi label stratified split\n",
            "Diagnosis multi-label stratified split results:\n",
            "diagnosis_fold\n",
            "0    18\n",
            "1    67\n",
            "2    16\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Fold 0 label distribution:\n",
            "diagnosis\n",
            "[7]                         0.222222\n",
            "[9, 8]                      0.111111\n",
            "[9, 7, 4, 8]                0.055556\n",
            "[16, 7, 8]                  0.055556\n",
            "[5, 6]                      0.055556\n",
            "[2, 4, 17, 7, 8, 10, 18]    0.055556\n",
            "[16, 8]                     0.055556\n",
            "[10, 3]                     0.055556\n",
            "[7, 1]                      0.055556\n",
            "[17, 6, 1, 8, 10]           0.055556\n",
            "[7, 3, 8]                   0.055556\n",
            "[9]                         0.055556\n",
            "[16, 7, 8, 10, 3]           0.055556\n",
            "[17]                        0.055556\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Fold 1 label distribution:\n",
            "diagnosis\n",
            "[7]                     0.164179\n",
            "[8]                     0.119403\n",
            "[16]                    0.044776\n",
            "[7, 8]                  0.044776\n",
            "[17]                    0.044776\n",
            "[10, 7]                 0.029851\n",
            "[3]                     0.029851\n",
            "[16, 8]                 0.029851\n",
            "[9]                     0.029851\n",
            "[4, 7, 3, 8]            0.014925\n",
            "[5, 16, 4, 7, 8]        0.014925\n",
            "[16, 17, 7, 1, 8]       0.014925\n",
            "[4, 7, 17, 9]           0.014925\n",
            "[7, 3]                  0.014925\n",
            "[10, 17, 6]             0.014925\n",
            "[4, 12, 5, 6, 7, 10]    0.014925\n",
            "[16, 6]                 0.014925\n",
            "[1, 17, 3, 8]           0.014925\n",
            "[10, 7, 1, 8]           0.014925\n",
            "[7, 10]                 0.014925\n",
            "[10, 7, 1]              0.014925\n",
            "[7, 9, 17]              0.014925\n",
            "[9, 3]                  0.014925\n",
            "[10, 9, 3]              0.014925\n",
            "[7, 9, 6, 8]            0.014925\n",
            "[4, 1, 2]               0.014925\n",
            "[17, 3]                 0.014925\n",
            "[7, 1, 8]               0.014925\n",
            "[17, 8]                 0.014925\n",
            "[10, 7, 3, 8]           0.014925\n",
            "[5]                     0.014925\n",
            "[10, 9]                 0.014925\n",
            "[1]                     0.014925\n",
            "[6]                     0.014925\n",
            "[6, 8]                  0.014925\n",
            "[8, 6]                  0.014925\n",
            "[5, 16, 1, 8, 10]       0.014925\n",
            "[10, 18, 3, 8]          0.014925\n",
            "[4, 9, 7]               0.014925\n",
            "[5, 7, 8]               0.014925\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Fold 2 label distribution:\n",
            "diagnosis\n",
            "[7]                         0.2500\n",
            "[16, 6, 7, 1, 8, 10, 18]    0.0625\n",
            "[17, 3]                     0.0625\n",
            "[5]                         0.0625\n",
            "[16, 7]                     0.0625\n",
            "[4, 1, 8]                   0.0625\n",
            "[8]                         0.0625\n",
            "[9, 17]                     0.0625\n",
            "[10, 7, 8]                  0.0625\n",
            "[10, 16, 9, 8]              0.0625\n",
            "[7, 6, 8]                   0.0625\n",
            "[9, 8]                      0.0625\n",
            "[3]                         0.0625\n",
            "Name: proportion, dtype: float64\n",
            "preparing split for few-shot learning\n",
            "Ratio: 10\n",
            "mortality 10\n",
            "mortality: Excluded 57 samples from train, 16 samples from valid\n",
            "readmission 10\n",
            "readmission: Excluded 52 samples from train, 16 samples from valid\n",
            "los_3day 10\n",
            "los_3day: Excluded 55 samples from train, 16 samples from valid\n",
            "los_7day 10\n",
            "los_7day: Excluded 55 samples from train, 16 samples from valid\n",
            "diagnosis 10\n",
            "diagnosis: Excluded 54 samples from train, 13 samples from valid\n",
            "\n",
            "mortality label distribution:\n",
            "Train set:\n",
            "mortality\n",
            "0    0.928571\n",
            "1    0.071429\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "mortality\n",
            "0    1.0\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "readmission label distribution:\n",
            "Train set:\n",
            "readmission\n",
            "0    0.923077\n",
            "1    0.076923\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "readmission\n",
            "0    0.75\n",
            "1    0.25\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "los_3day label distribution:\n",
            "Train set:\n",
            "los_3day\n",
            "0    0.538462\n",
            "1    0.461538\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "los_3day\n",
            "1    0.75\n",
            "0    0.25\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "los_7day label distribution:\n",
            "Train set:\n",
            "los_7day\n",
            "0    0.923077\n",
            "1    0.076923\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "los_7day\n",
            "0    1.0\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "diagnosis label distribution:\n",
            "Train set:\n",
            "diagnosis\n",
            "[7]                  0.153846\n",
            "[16, 17, 7, 1, 8]    0.076923\n",
            "[5, 16, 4, 7, 8]     0.076923\n",
            "[7, 3]               0.076923\n",
            "[4, 7, 3, 8]         0.076923\n",
            "[10, 17, 6]          0.076923\n",
            "[10, 9, 3]           0.076923\n",
            "[16, 6]              0.076923\n",
            "[3]                  0.076923\n",
            "[17, 3]              0.076923\n",
            "[17]                 0.076923\n",
            "[5, 7, 8]            0.076923\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "diagnosis\n",
            "[8]          0.333333\n",
            "[7, 6, 8]    0.333333\n",
            "[9, 8]       0.333333\n",
            "Name: proportion, dtype: float64\n",
            "Ratio: 30\n",
            "mortality 30\n",
            "mortality: Excluded 57 samples from train, 16 samples from valid\n",
            "readmission 30\n",
            "readmission: Excluded 52 samples from train, 16 samples from valid\n",
            "los_3day 30\n",
            "los_3day: Excluded 55 samples from train, 16 samples from valid\n",
            "los_7day 30\n",
            "los_7day: Excluded 55 samples from train, 16 samples from valid\n",
            "diagnosis 30\n",
            "diagnosis: Excluded 54 samples from train, 13 samples from valid\n",
            "\n",
            "mortality label distribution:\n",
            "Train set:\n",
            "mortality\n",
            "0    0.928571\n",
            "1    0.071429\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "mortality\n",
            "0    1.0\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "readmission label distribution:\n",
            "Train set:\n",
            "readmission\n",
            "0    0.923077\n",
            "1    0.076923\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "readmission\n",
            "0    0.75\n",
            "1    0.25\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "los_3day label distribution:\n",
            "Train set:\n",
            "los_3day\n",
            "0    0.538462\n",
            "1    0.461538\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "los_3day\n",
            "1    0.75\n",
            "0    0.25\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "los_7day label distribution:\n",
            "Train set:\n",
            "los_7day\n",
            "0    0.923077\n",
            "1    0.076923\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "los_7day\n",
            "0    1.0\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "diagnosis label distribution:\n",
            "Train set:\n",
            "diagnosis\n",
            "[7]                  0.153846\n",
            "[16, 17, 7, 1, 8]    0.076923\n",
            "[5, 16, 4, 7, 8]     0.076923\n",
            "[7, 3]               0.076923\n",
            "[4, 7, 3, 8]         0.076923\n",
            "[10, 17, 6]          0.076923\n",
            "[10, 9, 3]           0.076923\n",
            "[16, 6]              0.076923\n",
            "[3]                  0.076923\n",
            "[17, 3]              0.076923\n",
            "[17]                 0.076923\n",
            "[5, 7, 8]            0.076923\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "diagnosis\n",
            "[8]          0.333333\n",
            "[7, 6, 8]    0.333333\n",
            "[9, 8]       0.333333\n",
            "Name: proportion, dtype: float64\n",
            "Ratio: 50\n",
            "mortality 50\n",
            "mortality: Excluded 57 samples from train, 16 samples from valid\n",
            "readmission 50\n",
            "readmission: Excluded 52 samples from train, 16 samples from valid\n",
            "los_3day 50\n",
            "los_3day: Excluded 55 samples from train, 16 samples from valid\n",
            "los_7day 50\n",
            "los_7day: Excluded 55 samples from train, 16 samples from valid\n",
            "diagnosis 50\n",
            "diagnosis: Excluded 54 samples from train, 13 samples from valid\n",
            "\n",
            "mortality label distribution:\n",
            "Train set:\n",
            "mortality\n",
            "0    0.928571\n",
            "1    0.071429\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "mortality\n",
            "0    1.0\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "readmission label distribution:\n",
            "Train set:\n",
            "readmission\n",
            "0    0.923077\n",
            "1    0.076923\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "readmission\n",
            "0    0.75\n",
            "1    0.25\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "los_3day label distribution:\n",
            "Train set:\n",
            "los_3day\n",
            "0    0.538462\n",
            "1    0.461538\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "los_3day\n",
            "1    0.75\n",
            "0    0.25\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "los_7day label distribution:\n",
            "Train set:\n",
            "los_7day\n",
            "0    0.923077\n",
            "1    0.076923\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "los_7day\n",
            "0    1.0\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "diagnosis label distribution:\n",
            "Train set:\n",
            "diagnosis\n",
            "[7]                  0.153846\n",
            "[16, 17, 7, 1, 8]    0.076923\n",
            "[5, 16, 4, 7, 8]     0.076923\n",
            "[7, 3]               0.076923\n",
            "[4, 7, 3, 8]         0.076923\n",
            "[10, 17, 6]          0.076923\n",
            "[10, 9, 3]           0.076923\n",
            "[16, 6]              0.076923\n",
            "[3]                  0.076923\n",
            "[17, 3]              0.076923\n",
            "[17]                 0.076923\n",
            "[5, 7, 8]            0.076923\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "diagnosis\n",
            "[8]          0.333333\n",
            "[7, 6, 8]    0.333333\n",
            "[9, 8]       0.333333\n",
            "Name: proportion, dtype: float64\n",
            "Ratio: 70\n",
            "mortality 70\n",
            "mortality: Excluded 57 samples from train, 16 samples from valid\n",
            "readmission 70\n",
            "readmission: Excluded 52 samples from train, 16 samples from valid\n",
            "los_3day 70\n",
            "los_3day: Excluded 55 samples from train, 16 samples from valid\n",
            "los_7day 70\n",
            "los_7day: Excluded 55 samples from train, 16 samples from valid\n",
            "diagnosis 70\n",
            "diagnosis: Excluded 54 samples from train, 13 samples from valid\n",
            "\n",
            "mortality label distribution:\n",
            "Train set:\n",
            "mortality\n",
            "0    0.928571\n",
            "1    0.071429\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "mortality\n",
            "0    1.0\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "readmission label distribution:\n",
            "Train set:\n",
            "readmission\n",
            "0    0.923077\n",
            "1    0.076923\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "readmission\n",
            "0    0.75\n",
            "1    0.25\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "los_3day label distribution:\n",
            "Train set:\n",
            "los_3day\n",
            "0    0.538462\n",
            "1    0.461538\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "los_3day\n",
            "1    0.75\n",
            "0    0.25\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "los_7day label distribution:\n",
            "Train set:\n",
            "los_7day\n",
            "0    0.923077\n",
            "1    0.076923\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "los_7day\n",
            "0    1.0\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "diagnosis label distribution:\n",
            "Train set:\n",
            "diagnosis\n",
            "[7]                  0.153846\n",
            "[16, 17, 7, 1, 8]    0.076923\n",
            "[5, 16, 4, 7, 8]     0.076923\n",
            "[7, 3]               0.076923\n",
            "[4, 7, 3, 8]         0.076923\n",
            "[10, 17, 6]          0.076923\n",
            "[10, 9, 3]           0.076923\n",
            "[16, 6]              0.076923\n",
            "[3]                  0.076923\n",
            "[17, 3]              0.076923\n",
            "[17]                 0.076923\n",
            "[5, 7, 8]            0.076923\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "diagnosis\n",
            "[8]          0.333333\n",
            "[7, 6, 8]    0.333333\n",
            "[9, 8]       0.333333\n",
            "Name: proportion, dtype: float64\n",
            "Ratio: 90\n",
            "mortality 90\n",
            "mortality: Excluded 57 samples from train, 16 samples from valid\n",
            "readmission 90\n",
            "readmission: Excluded 52 samples from train, 16 samples from valid\n",
            "los_3day 90\n",
            "los_3day: Excluded 55 samples from train, 16 samples from valid\n",
            "los_7day 90\n",
            "los_7day: Excluded 55 samples from train, 16 samples from valid\n",
            "diagnosis 90\n",
            "diagnosis: Excluded 54 samples from train, 13 samples from valid\n",
            "\n",
            "mortality label distribution:\n",
            "Train set:\n",
            "mortality\n",
            "0    0.928571\n",
            "1    0.071429\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "mortality\n",
            "0    1.0\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "readmission label distribution:\n",
            "Train set:\n",
            "readmission\n",
            "0    0.923077\n",
            "1    0.076923\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "readmission\n",
            "0    0.75\n",
            "1    0.25\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "los_3day label distribution:\n",
            "Train set:\n",
            "los_3day\n",
            "0    0.538462\n",
            "1    0.461538\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "los_3day\n",
            "1    0.75\n",
            "0    0.25\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "los_7day label distribution:\n",
            "Train set:\n",
            "los_7day\n",
            "0    0.923077\n",
            "1    0.076923\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "los_7day\n",
            "0    1.0\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "diagnosis label distribution:\n",
            "Train set:\n",
            "diagnosis\n",
            "[7]                  0.153846\n",
            "[16, 17, 7, 1, 8]    0.076923\n",
            "[5, 16, 4, 7, 8]     0.076923\n",
            "[7, 3]               0.076923\n",
            "[4, 7, 3, 8]         0.076923\n",
            "[10, 17, 6]          0.076923\n",
            "[10, 9, 3]           0.076923\n",
            "[16, 6]              0.076923\n",
            "[3]                  0.076923\n",
            "[17, 3]              0.076923\n",
            "[17]                 0.076923\n",
            "[5, 7, 8]            0.076923\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "diagnosis\n",
            "[8]          0.333333\n",
            "[7, 6, 8]    0.333333\n",
            "[9, 8]       0.333333\n",
            "Name: proportion, dtype: float64\n",
            "Ratio: 100\n",
            "mortality 100\n",
            "mortality: Excluded 0 samples from train, 0 samples from valid\n",
            "readmission 100\n",
            "readmission: Excluded 0 samples from train, 0 samples from valid\n",
            "los_3day 100\n",
            "los_3day: Excluded 0 samples from train, 0 samples from valid\n",
            "los_7day 100\n",
            "los_7day: Excluded 0 samples from train, 0 samples from valid\n",
            "diagnosis 100\n",
            "diagnosis: Excluded 0 samples from train, 0 samples from valid\n",
            "\n",
            "mortality label distribution:\n",
            "Train set:\n",
            "mortality\n",
            "0    0.957746\n",
            "1    0.042254\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "mortality\n",
            "0    1.0\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "readmission label distribution:\n",
            "Train set:\n",
            "readmission\n",
            "0    0.876923\n",
            "1    0.123077\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "readmission\n",
            "0    0.8\n",
            "1    0.2\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "los_3day label distribution:\n",
            "Train set:\n",
            "los_3day\n",
            "0    0.705882\n",
            "1    0.294118\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "los_3day\n",
            "0    0.55\n",
            "1    0.45\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "los_7day label distribution:\n",
            "Train set:\n",
            "los_7day\n",
            "0    0.926471\n",
            "1    0.073529\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "los_7day\n",
            "0    0.95\n",
            "1    0.05\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "diagnosis label distribution:\n",
            "Train set:\n",
            "diagnosis\n",
            "[7]                     0.164179\n",
            "[8]                     0.119403\n",
            "[16]                    0.044776\n",
            "[7, 8]                  0.044776\n",
            "[17]                    0.044776\n",
            "[10, 7]                 0.029851\n",
            "[3]                     0.029851\n",
            "[16, 8]                 0.029851\n",
            "[9]                     0.029851\n",
            "[4, 7, 3, 8]            0.014925\n",
            "[5, 16, 4, 7, 8]        0.014925\n",
            "[16, 17, 7, 1, 8]       0.014925\n",
            "[4, 7, 17, 9]           0.014925\n",
            "[7, 3]                  0.014925\n",
            "[10, 17, 6]             0.014925\n",
            "[4, 12, 5, 6, 7, 10]    0.014925\n",
            "[16, 6]                 0.014925\n",
            "[1, 17, 3, 8]           0.014925\n",
            "[10, 7, 1, 8]           0.014925\n",
            "[7, 10]                 0.014925\n",
            "[10, 7, 1]              0.014925\n",
            "[7, 9, 17]              0.014925\n",
            "[9, 3]                  0.014925\n",
            "[10, 9, 3]              0.014925\n",
            "[7, 9, 6, 8]            0.014925\n",
            "[4, 1, 2]               0.014925\n",
            "[17, 3]                 0.014925\n",
            "[7, 1, 8]               0.014925\n",
            "[17, 8]                 0.014925\n",
            "[10, 7, 3, 8]           0.014925\n",
            "[5]                     0.014925\n",
            "[10, 9]                 0.014925\n",
            "[1]                     0.014925\n",
            "[6]                     0.014925\n",
            "[6, 8]                  0.014925\n",
            "[8, 6]                  0.014925\n",
            "[5, 16, 1, 8, 10]       0.014925\n",
            "[10, 18, 3, 8]          0.014925\n",
            "[4, 9, 7]               0.014925\n",
            "[5, 7, 8]               0.014925\n",
            "Name: proportion, dtype: float64\n",
            "Valid set:\n",
            "diagnosis\n",
            "[7]                         0.2500\n",
            "[16, 6, 7, 1, 8, 10, 18]    0.0625\n",
            "[17, 3]                     0.0625\n",
            "[5]                         0.0625\n",
            "[16, 7]                     0.0625\n",
            "[4, 1, 8]                   0.0625\n",
            "[8]                         0.0625\n",
            "[9, 17]                     0.0625\n",
            "[10, 7, 8]                  0.0625\n",
            "[10, 16, 9, 8]              0.0625\n",
            "[7, 6, 8]                   0.0625\n",
            "[9, 8]                      0.0625\n",
            "[3]                         0.0625\n",
            "Name: proportion, dtype: float64\n",
            "eicu dataframe pickle file has been loaded\n",
            "value mode :  NV\n",
            "codeemb feature index save_name code_index_NV\n",
            "tokenization for preparing descemb input with NV mode\n",
            "100% 101/101 [00:00<00:00, 133.87it/s]\n",
            "eicu dataframe pickle file has been loaded\n",
            "value mode :  VA\n",
            "codeemb feature index save_name code_index_VA\n",
            "tokenization for preparing descemb input with VA mode\n",
            "100% 101/101 [00:00<00:00, 112.20it/s]\n",
            "eicu dataframe pickle file has been loaded\n",
            "value mode :  DSVA\n",
            "codeemb feature index save_name code_index_DSVA\n",
            "tokenization for preparing descemb input with DSVA mode\n",
            "100% 101/101 [00:01<00:00, 67.65it/s]\n",
            "[Processing] transform token_type_ids with value encoding\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    6.5s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    7.4s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    9.8s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   15.3s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   18.7s\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   21.3s\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:   23.9s\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:   26.9s\n",
            "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   30.8s\n",
            "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:   35.6s\n",
            "[Parallel(n_jobs=-1)]: Done 101 out of 101 | elapsed:   37.1s finished\n",
            "[End] transform np.array into DataFrame\n",
            "eicu dataframe pickle file has been loaded\n",
            "value mode :  VC\n",
            "codeemb feature index save_name code_index_VC\n",
            "tokenization for preparing descemb input with VC mode\n",
            "100% 101/101 [00:00<00:00, 135.92it/s]\n",
            "preprocessing for eicu has been done.\n"
          ]
        }
      ],
      "source": [
        "''' mimiciii '''\n",
        "# data = 'mimiciii'\n",
        "# data_src_directory = 'datasets/data_input_path/mimic'\n",
        "# data_src_directory = 'datasets/data_input_path/mimic/mlm' # uncomment this line if you want to preprocess mimiciii mlm data\n",
        "\n",
        "''' eicu '''\n",
        "data = 'eicu' # uncomment this line if you want to preprocess eicu data\n",
        "data_src_directory = 'datasets/data_input_path/eicu' # uncomment this line if you want to preprocess eicu data\n",
        "\n",
        "run_ready_directory = 'datasets/data_output_path'\n",
        "ccs_dx_tool_path = 'datasets/data_input_path/ccs_multi_dx_tool_2015.csv'\n",
        "icd10to9_path = 'datasets/data_input_path/icd10cmtoicd9gem.csv'\n",
        "\n",
        "# preprocess the data\n",
        "!python3 preprocess/preprocess_main.py --src_data {data} --dataset_path {data_src_directory} --dest_path {run_ready_directory} --ccs_dx_tool_path {ccs_dx_tool_path} --icd10to9_path {icd10to9_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2341ec0b-4fc9-4e72-9e99-fa355237c294",
      "metadata": {
        "id": "2341ec0b-4fc9-4e72-9e99-fa355237c294"
      },
      "source": [
        "**Note**\n",
        "- **Computational Resources**: Preprocessing is computationally intensive. The machine configuration (e.g., CPU cores and RAM) should match the recommended specifications (described in the **Training** section below).\n",
        "- **Data Security and Compliance**: Always comply with the licensing agreements of the data sources, particularly regarding the handling and privacy of sensitive healthcare data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5885ea37-c50d-4a19-84f5-dac5d5b1cbce",
      "metadata": {
        "id": "5885ea37-c50d-4a19-84f5-dac5d5b1cbce"
      },
      "source": [
        "## Model\n",
        "\n",
        "### References and Links\n",
        "\n",
        "**Citation to the original paper**: [Unifying Heterogeneous Electronic Health Records Systems via Text-Based Code Embedding](https://arxiv.org/abs/2108.03625)\n",
        "\n",
        "**Link to the paper's Github repo**: [Visit the repository](https://github.com/hoon9405/DescEmb?tab=readme-ov-file)\n",
        "\n",
        "\n",
        "### Model Description\n",
        "The DescEmb (Description-based Embedding) model utilizes advanced NLP techniques to handle heterogeneous data from Electronic Health Records (EHRs) systems. The key components used in training these models are:\n",
        "\n",
        "- **Masked Language Modeling (MLM)**: This approach is inspired by BERT (Bidirectional Encoder Representations from Transformers) and is used to pre-train the DescEmb model. It helps the model learn contextual relationships between words in medical notes by predicting randomly masked words in a sentence.\n",
        "- **Word2Vec Embedding**: This method is used for training a CodeEmb model, which focuses on learning vector representations of medical codes. Unlike MLM, Word2Vec directly predicts surrounding words given a target word, which helps capture the semantic relationships between different medical codes.\n",
        "\n",
        "These methods are crucial for enabling the DescEmb model to generate embeddings that can unify disparate EHR systems, allowing for improved performance on various predictive tasks such as readmission, mortality, and length of stay predictions.\n",
        "\n",
        "### Implementation Code\n",
        "Below are code snippets for pre-training and fine-tuning the models.\n",
        "\n",
        "#### Pre-training the DescEmb Model with MLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36ebceb7-6c0b-40ab-b1f8-a1970189d38b",
      "metadata": {
        "id": "36ebceb7-6c0b-40ab-b1f8-a1970189d38b"
      },
      "source": [
        "#### Pre-train a CodeEmb model with Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "127ca27b-7aae-41fa-b1cc-827b6d621cfc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "127ca27b-7aae-41fa-b1cc-827b6d621cfc",
        "outputId": "3ee2c789-e601-4a2a-dde1-29c1a76b1fcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-05-08 00:22:25 | INFO numexpr.utils NumExpr defaulting to 2 threads.)))\n",
            "Type of pos_pair: <class 'dict'>\n",
            "[2024-05-08 00:22:29,625][trainers.word2vec_trainer][INFO] - epoch: 0, loss: 1.386\n",
            "[2024-05-08 00:22:29,625][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,627][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,668][trainers.word2vec_trainer][INFO] - epoch: 1, loss: 1.386\n",
            "Validation AUROC increased (0.000000 --> -1.386131)\n",
            "[2024-05-08 00:22:29,668][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,670][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,711][trainers.word2vec_trainer][INFO] - epoch: 2, loss: 1.386\n",
            "Validation AUROC increased (-1.386131 --> -1.385945)\n",
            "[2024-05-08 00:22:29,711][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,713][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,752][trainers.word2vec_trainer][INFO] - epoch: 3, loss: 1.386\n",
            "Validation AUROC increased (-1.385945 --> -1.385707)\n",
            "[2024-05-08 00:22:29,752][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,753][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,791][trainers.word2vec_trainer][INFO] - epoch: 4, loss: 1.386\n",
            "Validation AUROC increased (-1.385707 --> -1.385517)\n",
            "[2024-05-08 00:22:29,791][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,793][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,831][trainers.word2vec_trainer][INFO] - epoch: 5, loss: 1.385\n",
            "Validation AUROC increased (-1.385517 --> -1.385272)\n",
            "[2024-05-08 00:22:29,831][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,833][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,870][trainers.word2vec_trainer][INFO] - epoch: 6, loss: 1.385\n",
            "Validation AUROC increased (-1.385272 --> -1.384830)\n",
            "[2024-05-08 00:22:29,870][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,872][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,912][trainers.word2vec_trainer][INFO] - epoch: 7, loss: 1.384\n",
            "Validation AUROC increased (-1.384830 --> -1.384475)\n",
            "[2024-05-08 00:22:29,912][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,914][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,951][trainers.word2vec_trainer][INFO] - epoch: 8, loss: 1.384\n",
            "Validation AUROC increased (-1.384475 --> -1.383971)\n",
            "[2024-05-08 00:22:29,951][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,953][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,992][trainers.word2vec_trainer][INFO] - epoch: 9, loss: 1.383\n",
            "Validation AUROC increased (-1.383971 --> -1.383361)\n",
            "[2024-05-08 00:22:29,992][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:29,994][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,032][trainers.word2vec_trainer][INFO] - epoch: 10, loss: 1.383\n",
            "Validation AUROC increased (-1.383361 --> -1.382599)\n",
            "[2024-05-08 00:22:30,032][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,034][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,072][trainers.word2vec_trainer][INFO] - epoch: 11, loss: 1.382\n",
            "Validation AUROC increased (-1.382599 --> -1.381804)\n",
            "[2024-05-08 00:22:30,072][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,074][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,112][trainers.word2vec_trainer][INFO] - epoch: 12, loss: 1.381\n",
            "Validation AUROC increased (-1.381804 --> -1.380934)\n",
            "[2024-05-08 00:22:30,112][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,114][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,155][trainers.word2vec_trainer][INFO] - epoch: 13, loss: 1.380\n",
            "Validation AUROC increased (-1.380934 --> -1.379622)\n",
            "[2024-05-08 00:22:30,155][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,157][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,200][trainers.word2vec_trainer][INFO] - epoch: 14, loss: 1.378\n",
            "Validation AUROC increased (-1.379622 --> -1.378312)\n",
            "[2024-05-08 00:22:30,201][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,203][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,240][trainers.word2vec_trainer][INFO] - epoch: 15, loss: 1.377\n",
            "Validation AUROC increased (-1.378312 --> -1.376707)\n",
            "[2024-05-08 00:22:30,241][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,242][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,283][trainers.word2vec_trainer][INFO] - epoch: 16, loss: 1.375\n",
            "Validation AUROC increased (-1.376707 --> -1.374991)\n",
            "[2024-05-08 00:22:30,283][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,286][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,327][trainers.word2vec_trainer][INFO] - epoch: 17, loss: 1.373\n",
            "Validation AUROC increased (-1.374991 --> -1.372868)\n",
            "[2024-05-08 00:22:30,327][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,329][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,367][trainers.word2vec_trainer][INFO] - epoch: 18, loss: 1.371\n",
            "Validation AUROC increased (-1.372868 --> -1.370728)\n",
            "[2024-05-08 00:22:30,367][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,369][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,408][trainers.word2vec_trainer][INFO] - epoch: 19, loss: 1.368\n",
            "Validation AUROC increased (-1.370728 --> -1.367805)\n",
            "[2024-05-08 00:22:30,409][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,410][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,449][trainers.word2vec_trainer][INFO] - epoch: 20, loss: 1.365\n",
            "Validation AUROC increased (-1.367805 --> -1.365004)\n",
            "[2024-05-08 00:22:30,449][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,451][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,492][trainers.word2vec_trainer][INFO] - epoch: 21, loss: 1.361\n",
            "Validation AUROC increased (-1.365004 --> -1.361497)\n",
            "[2024-05-08 00:22:30,492][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,494][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,541][trainers.word2vec_trainer][INFO] - epoch: 22, loss: 1.358\n",
            "Validation AUROC increased (-1.361497 --> -1.357785)\n",
            "[2024-05-08 00:22:30,541][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,544][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,584][trainers.word2vec_trainer][INFO] - epoch: 23, loss: 1.354\n",
            "Validation AUROC increased (-1.357785 --> -1.353569)\n",
            "[2024-05-08 00:22:30,584][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,586][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,624][trainers.word2vec_trainer][INFO] - epoch: 24, loss: 1.349\n",
            "Validation AUROC increased (-1.353569 --> -1.349403)\n",
            "[2024-05-08 00:22:30,624][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,626][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,663][trainers.word2vec_trainer][INFO] - epoch: 25, loss: 1.344\n",
            "Validation AUROC increased (-1.349403 --> -1.344122)\n",
            "[2024-05-08 00:22:30,663][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,665][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,706][trainers.word2vec_trainer][INFO] - epoch: 26, loss: 1.339\n",
            "Validation AUROC increased (-1.344122 --> -1.338885)\n",
            "[2024-05-08 00:22:30,706][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,708][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,747][trainers.word2vec_trainer][INFO] - epoch: 27, loss: 1.333\n",
            "Validation AUROC increased (-1.338885 --> -1.332813)\n",
            "[2024-05-08 00:22:30,748][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,750][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,793][trainers.word2vec_trainer][INFO] - epoch: 28, loss: 1.327\n",
            "Validation AUROC increased (-1.332813 --> -1.326764)\n",
            "[2024-05-08 00:22:30,793][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,795][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,833][trainers.word2vec_trainer][INFO] - epoch: 29, loss: 1.320\n",
            "Validation AUROC increased (-1.326764 --> -1.319690)\n",
            "[2024-05-08 00:22:30,833][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,835][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,874][trainers.word2vec_trainer][INFO] - epoch: 30, loss: 1.312\n",
            "Validation AUROC increased (-1.319690 --> -1.312261)\n",
            "[2024-05-08 00:22:30,874][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,876][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,915][trainers.word2vec_trainer][INFO] - epoch: 31, loss: 1.305\n",
            "Validation AUROC increased (-1.312261 --> -1.304705)\n",
            "[2024-05-08 00:22:30,915][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,917][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,955][trainers.word2vec_trainer][INFO] - epoch: 32, loss: 1.297\n",
            "Validation AUROC increased (-1.304705 --> -1.296592)\n",
            "[2024-05-08 00:22:30,955][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,957][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,994][trainers.word2vec_trainer][INFO] - epoch: 33, loss: 1.288\n",
            "Validation AUROC increased (-1.296592 --> -1.287707)\n",
            "[2024-05-08 00:22:30,994][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:30,996][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,033][trainers.word2vec_trainer][INFO] - epoch: 34, loss: 1.278\n",
            "Validation AUROC increased (-1.287707 --> -1.278476)\n",
            "[2024-05-08 00:22:31,034][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,035][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,072][trainers.word2vec_trainer][INFO] - epoch: 35, loss: 1.268\n",
            "Validation AUROC increased (-1.278476 --> -1.268459)\n",
            "[2024-05-08 00:22:31,072][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,074][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,118][trainers.word2vec_trainer][INFO] - epoch: 36, loss: 1.258\n",
            "Validation AUROC increased (-1.268459 --> -1.257756)\n",
            "[2024-05-08 00:22:31,119][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,120][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,165][trainers.word2vec_trainer][INFO] - epoch: 37, loss: 1.247\n",
            "Validation AUROC increased (-1.257756 --> -1.246855)\n",
            "[2024-05-08 00:22:31,165][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,167][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,206][trainers.word2vec_trainer][INFO] - epoch: 38, loss: 1.236\n",
            "Validation AUROC increased (-1.246855 --> -1.236126)\n",
            "[2024-05-08 00:22:31,207][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,208][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,247][trainers.word2vec_trainer][INFO] - epoch: 39, loss: 1.226\n",
            "Validation AUROC increased (-1.236126 --> -1.225610)\n",
            "[2024-05-08 00:22:31,247][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,249][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,286][trainers.word2vec_trainer][INFO] - epoch: 40, loss: 1.215\n",
            "Validation AUROC increased (-1.225610 --> -1.215092)\n",
            "[2024-05-08 00:22:31,287][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,289][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,325][trainers.word2vec_trainer][INFO] - epoch: 41, loss: 1.201\n",
            "Validation AUROC increased (-1.215092 --> -1.200539)\n",
            "[2024-05-08 00:22:31,325][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,327][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,365][trainers.word2vec_trainer][INFO] - epoch: 42, loss: 1.190\n",
            "Validation AUROC increased (-1.200539 --> -1.190033)\n",
            "[2024-05-08 00:22:31,365][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,367][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,410][trainers.word2vec_trainer][INFO] - epoch: 43, loss: 1.177\n",
            "Validation AUROC increased (-1.190033 --> -1.176576)\n",
            "[2024-05-08 00:22:31,410][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,412][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,451][trainers.word2vec_trainer][INFO] - epoch: 44, loss: 1.164\n",
            "Validation AUROC increased (-1.176576 --> -1.163934)\n",
            "[2024-05-08 00:22:31,451][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,453][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,493][trainers.word2vec_trainer][INFO] - epoch: 45, loss: 1.152\n",
            "Validation AUROC increased (-1.163934 --> -1.152116)\n",
            "[2024-05-08 00:22:31,493][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,495][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,535][trainers.word2vec_trainer][INFO] - epoch: 46, loss: 1.139\n",
            "Validation AUROC increased (-1.152116 --> -1.138930)\n",
            "[2024-05-08 00:22:31,535][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,537][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,592][trainers.word2vec_trainer][INFO] - epoch: 47, loss: 1.124\n",
            "Validation AUROC increased (-1.138930 --> -1.124479)\n",
            "[2024-05-08 00:22:31,592][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,594][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,636][trainers.word2vec_trainer][INFO] - epoch: 48, loss: 1.113\n",
            "Validation AUROC increased (-1.124479 --> -1.112517)\n",
            "[2024-05-08 00:22:31,637][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,638][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,677][trainers.word2vec_trainer][INFO] - epoch: 49, loss: 1.099\n",
            "Validation AUROC increased (-1.112517 --> -1.099475)\n",
            "[2024-05-08 00:22:31,678][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,679][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,719][trainers.word2vec_trainer][INFO] - epoch: 50, loss: 1.086\n",
            "Validation AUROC increased (-1.099475 --> -1.086368)\n",
            "[2024-05-08 00:22:31,719][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,721][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,760][trainers.word2vec_trainer][INFO] - epoch: 51, loss: 1.075\n",
            "Validation AUROC increased (-1.086368 --> -1.075194)\n",
            "[2024-05-08 00:22:31,760][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,762][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,802][trainers.word2vec_trainer][INFO] - epoch: 52, loss: 1.060\n",
            "Validation AUROC increased (-1.075194 --> -1.059577)\n",
            "[2024-05-08 00:22:31,803][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,804][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,843][trainers.word2vec_trainer][INFO] - epoch: 53, loss: 1.048\n",
            "Validation AUROC increased (-1.059577 --> -1.047665)\n",
            "[2024-05-08 00:22:31,844][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,846][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,884][trainers.word2vec_trainer][INFO] - epoch: 54, loss: 1.032\n",
            "Validation AUROC increased (-1.047665 --> -1.032229)\n",
            "[2024-05-08 00:22:31,884][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,886][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,933][trainers.word2vec_trainer][INFO] - epoch: 55, loss: 1.023\n",
            "Validation AUROC increased (-1.032229 --> -1.022509)\n",
            "[2024-05-08 00:22:31,934][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,936][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,975][trainers.word2vec_trainer][INFO] - epoch: 56, loss: 1.010\n",
            "Validation AUROC increased (-1.022509 --> -1.009587)\n",
            "[2024-05-08 00:22:31,975][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:31,977][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,016][trainers.word2vec_trainer][INFO] - epoch: 57, loss: 0.999\n",
            "Validation AUROC increased (-1.009587 --> -0.998853)\n",
            "[2024-05-08 00:22:32,017][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,018][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,057][trainers.word2vec_trainer][INFO] - epoch: 58, loss: 0.987\n",
            "Validation AUROC increased (-0.998853 --> -0.986793)\n",
            "[2024-05-08 00:22:32,057][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,059][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,098][trainers.word2vec_trainer][INFO] - epoch: 59, loss: 0.976\n",
            "Validation AUROC increased (-0.986793 --> -0.975806)\n",
            "[2024-05-08 00:22:32,098][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,100][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,141][trainers.word2vec_trainer][INFO] - epoch: 60, loss: 0.961\n",
            "Validation AUROC increased (-0.975806 --> -0.961382)\n",
            "[2024-05-08 00:22:32,142][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,143][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,185][trainers.word2vec_trainer][INFO] - epoch: 61, loss: 0.951\n",
            "Validation AUROC increased (-0.961382 --> -0.951069)\n",
            "[2024-05-08 00:22:32,185][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,187][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,228][trainers.word2vec_trainer][INFO] - epoch: 62, loss: 0.941\n",
            "Validation AUROC increased (-0.951069 --> -0.940729)\n",
            "[2024-05-08 00:22:32,229][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,230][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,268][trainers.word2vec_trainer][INFO] - epoch: 63, loss: 0.932\n",
            "Validation AUROC increased (-0.940729 --> -0.932430)\n",
            "[2024-05-08 00:22:32,268][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,270][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,313][trainers.word2vec_trainer][INFO] - epoch: 64, loss: 0.919\n",
            "Validation AUROC increased (-0.932430 --> -0.918694)\n",
            "[2024-05-08 00:22:32,313][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,315][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,354][trainers.word2vec_trainer][INFO] - epoch: 65, loss: 0.909\n",
            "Validation AUROC increased (-0.918694 --> -0.908877)\n",
            "[2024-05-08 00:22:32,354][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,356][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,396][trainers.word2vec_trainer][INFO] - epoch: 66, loss: 0.899\n",
            "Validation AUROC increased (-0.908877 --> -0.898920)\n",
            "[2024-05-08 00:22:32,396][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,398][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,438][trainers.word2vec_trainer][INFO] - epoch: 67, loss: 0.889\n",
            "Validation AUROC increased (-0.898920 --> -0.889115)\n",
            "[2024-05-08 00:22:32,438][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,440][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,479][trainers.word2vec_trainer][INFO] - epoch: 68, loss: 0.879\n",
            "Validation AUROC increased (-0.889115 --> -0.878537)\n",
            "[2024-05-08 00:22:32,479][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,481][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,528][trainers.word2vec_trainer][INFO] - epoch: 69, loss: 0.871\n",
            "Validation AUROC increased (-0.878537 --> -0.871385)\n",
            "[2024-05-08 00:22:32,529][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,530][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,569][trainers.word2vec_trainer][INFO] - epoch: 70, loss: 0.857\n",
            "Validation AUROC increased (-0.871385 --> -0.857098)\n",
            "[2024-05-08 00:22:32,569][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,571][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,619][trainers.word2vec_trainer][INFO] - epoch: 71, loss: 0.854\n",
            "Validation AUROC increased (-0.857098 --> -0.853648)\n",
            "[2024-05-08 00:22:32,620][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,622][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,660][trainers.word2vec_trainer][INFO] - epoch: 72, loss: 0.848\n",
            "Validation AUROC increased (-0.853648 --> -0.848485)\n",
            "[2024-05-08 00:22:32,660][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,661][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,699][trainers.word2vec_trainer][INFO] - epoch: 73, loss: 0.837\n",
            "Validation AUROC increased (-0.848485 --> -0.836739)\n",
            "[2024-05-08 00:22:32,699][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,702][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,746][trainers.word2vec_trainer][INFO] - epoch: 74, loss: 0.833\n",
            "Validation AUROC increased (-0.836739 --> -0.832950)\n",
            "[2024-05-08 00:22:32,746][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,748][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,786][trainers.word2vec_trainer][INFO] - epoch: 75, loss: 0.822\n",
            "Validation AUROC increased (-0.832950 --> -0.822174)\n",
            "[2024-05-08 00:22:32,786][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,788][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,827][trainers.word2vec_trainer][INFO] - epoch: 76, loss: 0.816\n",
            "Validation AUROC increased (-0.822174 --> -0.816046)\n",
            "[2024-05-08 00:22:32,827][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,829][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,870][trainers.word2vec_trainer][INFO] - epoch: 77, loss: 0.808\n",
            "Validation AUROC increased (-0.816046 --> -0.808234)\n",
            "[2024-05-08 00:22:32,870][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,872][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,911][trainers.word2vec_trainer][INFO] - epoch: 78, loss: 0.805\n",
            "Validation AUROC increased (-0.808234 --> -0.805161)\n",
            "[2024-05-08 00:22:32,911][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,913][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,953][trainers.word2vec_trainer][INFO] - epoch: 79, loss: 0.797\n",
            "Validation AUROC increased (-0.805161 --> -0.797083)\n",
            "[2024-05-08 00:22:32,953][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,955][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,993][trainers.word2vec_trainer][INFO] - epoch: 80, loss: 0.789\n",
            "Validation AUROC increased (-0.797083 --> -0.788567)\n",
            "[2024-05-08 00:22:32,993][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:32,995][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,035][trainers.word2vec_trainer][INFO] - epoch: 81, loss: 0.781\n",
            "Validation AUROC increased (-0.788567 --> -0.781437)\n",
            "[2024-05-08 00:22:33,035][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,037][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,078][trainers.word2vec_trainer][INFO] - epoch: 82, loss: 0.774\n",
            "Validation AUROC increased (-0.781437 --> -0.773898)\n",
            "[2024-05-08 00:22:33,078][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,080][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,120][trainers.word2vec_trainer][INFO] - epoch: 83, loss: 0.763\n",
            "Validation AUROC increased (-0.773898 --> -0.762972)\n",
            "[2024-05-08 00:22:33,120][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,122][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,164][trainers.word2vec_trainer][INFO] - epoch: 84, loss: 0.760\n",
            "Validation AUROC increased (-0.762972 --> -0.759515)\n",
            "[2024-05-08 00:22:33,164][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,166][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,207][trainers.word2vec_trainer][INFO] - epoch: 85, loss: 0.756\n",
            "Validation AUROC increased (-0.759515 --> -0.755859)\n",
            "[2024-05-08 00:22:33,207][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,209][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,245][trainers.word2vec_trainer][INFO] - epoch: 86, loss: 0.751\n",
            "Validation AUROC increased (-0.755859 --> -0.751123)\n",
            "[2024-05-08 00:22:33,246][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,247][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,284][trainers.word2vec_trainer][INFO] - epoch: 87, loss: 0.749\n",
            "Validation AUROC increased (-0.751123 --> -0.748566)\n",
            "[2024-05-08 00:22:33,285][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,286][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,326][trainers.word2vec_trainer][INFO] - epoch: 88, loss: 0.734\n",
            "Validation AUROC increased (-0.748566 --> -0.734231)\n",
            "[2024-05-08 00:22:33,327][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,328][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,366][trainers.word2vec_trainer][INFO] - epoch: 89, loss: 0.735\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:33,407][trainers.word2vec_trainer][INFO] - epoch: 90, loss: 0.730\n",
            "Validation AUROC increased (-0.734231 --> -0.729756)\n",
            "[2024-05-08 00:22:33,407][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,409][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,448][trainers.word2vec_trainer][INFO] - epoch: 91, loss: 0.721\n",
            "Validation AUROC increased (-0.729756 --> -0.720640)\n",
            "[2024-05-08 00:22:33,448][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,450][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,489][trainers.word2vec_trainer][INFO] - epoch: 92, loss: 0.724\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:33,530][trainers.word2vec_trainer][INFO] - epoch: 93, loss: 0.713\n",
            "Validation AUROC increased (-0.720640 --> -0.713310)\n",
            "[2024-05-08 00:22:33,530][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,532][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,570][trainers.word2vec_trainer][INFO] - epoch: 94, loss: 0.706\n",
            "Validation AUROC increased (-0.713310 --> -0.705845)\n",
            "[2024-05-08 00:22:33,570][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,572][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,620][trainers.word2vec_trainer][INFO] - epoch: 95, loss: 0.703\n",
            "Validation AUROC increased (-0.705845 --> -0.703325)\n",
            "[2024-05-08 00:22:33,620][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,622][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,664][trainers.word2vec_trainer][INFO] - epoch: 96, loss: 0.693\n",
            "Validation AUROC increased (-0.703325 --> -0.692907)\n",
            "[2024-05-08 00:22:33,664][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,666][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,704][trainers.word2vec_trainer][INFO] - epoch: 97, loss: 0.687\n",
            "Validation AUROC increased (-0.692907 --> -0.687298)\n",
            "[2024-05-08 00:22:33,705][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,706][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,744][trainers.word2vec_trainer][INFO] - epoch: 98, loss: 0.684\n",
            "Validation AUROC increased (-0.687298 --> -0.684168)\n",
            "[2024-05-08 00:22:33,744][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,745][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,782][trainers.word2vec_trainer][INFO] - epoch: 99, loss: 0.680\n",
            "Validation AUROC increased (-0.684168 --> -0.679692)\n",
            "[2024-05-08 00:22:33,782][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,784][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,824][trainers.word2vec_trainer][INFO] - epoch: 100, loss: 0.674\n",
            "Validation AUROC increased (-0.679692 --> -0.674258)\n",
            "[2024-05-08 00:22:33,824][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,826][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,862][trainers.word2vec_trainer][INFO] - epoch: 101, loss: 0.672\n",
            "Validation AUROC increased (-0.674258 --> -0.672066)\n",
            "[2024-05-08 00:22:33,862][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,864][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,901][trainers.word2vec_trainer][INFO] - epoch: 102, loss: 0.669\n",
            "Validation AUROC increased (-0.672066 --> -0.669448)\n",
            "[2024-05-08 00:22:33,901][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,902][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,941][trainers.word2vec_trainer][INFO] - epoch: 103, loss: 0.666\n",
            "Validation AUROC increased (-0.669448 --> -0.665534)\n",
            "[2024-05-08 00:22:33,941][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,943][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,981][trainers.word2vec_trainer][INFO] - epoch: 104, loss: 0.659\n",
            "Validation AUROC increased (-0.665534 --> -0.659159)\n",
            "[2024-05-08 00:22:33,981][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:33,982][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,027][trainers.word2vec_trainer][INFO] - epoch: 105, loss: 0.656\n",
            "Validation AUROC increased (-0.659159 --> -0.655713)\n",
            "[2024-05-08 00:22:34,027][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,029][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,068][trainers.word2vec_trainer][INFO] - epoch: 106, loss: 0.651\n",
            "Validation AUROC increased (-0.655713 --> -0.651137)\n",
            "[2024-05-08 00:22:34,068][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,070][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,107][trainers.word2vec_trainer][INFO] - epoch: 107, loss: 0.647\n",
            "Validation AUROC increased (-0.651137 --> -0.647478)\n",
            "[2024-05-08 00:22:34,108][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,109][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,150][trainers.word2vec_trainer][INFO] - epoch: 108, loss: 0.645\n",
            "Validation AUROC increased (-0.647478 --> -0.645367)\n",
            "[2024-05-08 00:22:34,150][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,152][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,192][trainers.word2vec_trainer][INFO] - epoch: 109, loss: 0.639\n",
            "Validation AUROC increased (-0.645367 --> -0.639128)\n",
            "[2024-05-08 00:22:34,192][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,194][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,232][trainers.word2vec_trainer][INFO] - epoch: 110, loss: 0.637\n",
            "Validation AUROC increased (-0.639128 --> -0.636843)\n",
            "[2024-05-08 00:22:34,232][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,234][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,272][trainers.word2vec_trainer][INFO] - epoch: 111, loss: 0.631\n",
            "Validation AUROC increased (-0.636843 --> -0.631041)\n",
            "[2024-05-08 00:22:34,272][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,274][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,314][trainers.word2vec_trainer][INFO] - epoch: 112, loss: 0.621\n",
            "Validation AUROC increased (-0.631041 --> -0.621260)\n",
            "[2024-05-08 00:22:34,314][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,318][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,356][trainers.word2vec_trainer][INFO] - epoch: 113, loss: 0.617\n",
            "Validation AUROC increased (-0.621260 --> -0.616763)\n",
            "[2024-05-08 00:22:34,356][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,358][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,396][trainers.word2vec_trainer][INFO] - epoch: 114, loss: 0.614\n",
            "Validation AUROC increased (-0.616763 --> -0.614009)\n",
            "[2024-05-08 00:22:34,396][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,398][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,436][trainers.word2vec_trainer][INFO] - epoch: 115, loss: 0.614\n",
            "Validation AUROC increased (-0.614009 --> -0.613884)\n",
            "[2024-05-08 00:22:34,436][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,438][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,477][trainers.word2vec_trainer][INFO] - epoch: 116, loss: 0.609\n",
            "Validation AUROC increased (-0.613884 --> -0.609032)\n",
            "[2024-05-08 00:22:34,477][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,479][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,515][trainers.word2vec_trainer][INFO] - epoch: 117, loss: 0.600\n",
            "Validation AUROC increased (-0.609032 --> -0.599560)\n",
            "[2024-05-08 00:22:34,515][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,517][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,558][trainers.word2vec_trainer][INFO] - epoch: 118, loss: 0.597\n",
            "Validation AUROC increased (-0.599560 --> -0.596965)\n",
            "[2024-05-08 00:22:34,558][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,560][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,604][trainers.word2vec_trainer][INFO] - epoch: 119, loss: 0.599\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:34,672][trainers.word2vec_trainer][INFO] - epoch: 120, loss: 0.603\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:34,732][trainers.word2vec_trainer][INFO] - epoch: 121, loss: 0.590\n",
            "Validation AUROC increased (-0.596965 --> -0.590217)\n",
            "[2024-05-08 00:22:34,733][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,736][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,794][trainers.word2vec_trainer][INFO] - epoch: 122, loss: 0.592\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:34,861][trainers.word2vec_trainer][INFO] - epoch: 123, loss: 0.575\n",
            "Validation AUROC increased (-0.590217 --> -0.575498)\n",
            "[2024-05-08 00:22:34,861][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,864][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,923][trainers.word2vec_trainer][INFO] - epoch: 124, loss: 0.580\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:34,980][trainers.word2vec_trainer][INFO] - epoch: 125, loss: 0.566\n",
            "Validation AUROC increased (-0.575498 --> -0.565670)\n",
            "[2024-05-08 00:22:34,980][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:34,983][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,043][trainers.word2vec_trainer][INFO] - epoch: 126, loss: 0.563\n",
            "Validation AUROC increased (-0.565670 --> -0.563274)\n",
            "[2024-05-08 00:22:35,043][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,046][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,104][trainers.word2vec_trainer][INFO] - epoch: 127, loss: 0.556\n",
            "Validation AUROC increased (-0.563274 --> -0.555784)\n",
            "[2024-05-08 00:22:35,104][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,107][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,172][trainers.word2vec_trainer][INFO] - epoch: 128, loss: 0.557\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:35,232][trainers.word2vec_trainer][INFO] - epoch: 129, loss: 0.555\n",
            "Validation AUROC increased (-0.555784 --> -0.554868)\n",
            "[2024-05-08 00:22:35,232][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,235][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,292][trainers.word2vec_trainer][INFO] - epoch: 130, loss: 0.552\n",
            "Validation AUROC increased (-0.554868 --> -0.551624)\n",
            "[2024-05-08 00:22:35,292][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,296][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,352][trainers.word2vec_trainer][INFO] - epoch: 131, loss: 0.542\n",
            "Validation AUROC increased (-0.551624 --> -0.541862)\n",
            "[2024-05-08 00:22:35,352][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,355][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,412][trainers.word2vec_trainer][INFO] - epoch: 132, loss: 0.541\n",
            "Validation AUROC increased (-0.541862 --> -0.540802)\n",
            "[2024-05-08 00:22:35,412][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,415][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,473][trainers.word2vec_trainer][INFO] - epoch: 133, loss: 0.539\n",
            "Validation AUROC increased (-0.540802 --> -0.538869)\n",
            "[2024-05-08 00:22:35,474][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,476][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,537][trainers.word2vec_trainer][INFO] - epoch: 134, loss: 0.533\n",
            "Validation AUROC increased (-0.538869 --> -0.533293)\n",
            "[2024-05-08 00:22:35,537][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,540][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,600][trainers.word2vec_trainer][INFO] - epoch: 135, loss: 0.530\n",
            "Validation AUROC increased (-0.533293 --> -0.529589)\n",
            "[2024-05-08 00:22:35,600][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,602][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,662][trainers.word2vec_trainer][INFO] - epoch: 136, loss: 0.531\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:35,730][trainers.word2vec_trainer][INFO] - epoch: 137, loss: 0.527\n",
            "Validation AUROC increased (-0.529589 --> -0.526963)\n",
            "[2024-05-08 00:22:35,730][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,733][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,793][trainers.word2vec_trainer][INFO] - epoch: 138, loss: 0.524\n",
            "Validation AUROC increased (-0.526963 --> -0.524462)\n",
            "[2024-05-08 00:22:35,793][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,796][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,853][trainers.word2vec_trainer][INFO] - epoch: 139, loss: 0.520\n",
            "Validation AUROC increased (-0.524462 --> -0.519873)\n",
            "[2024-05-08 00:22:35,853][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,856][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,913][trainers.word2vec_trainer][INFO] - epoch: 140, loss: 0.515\n",
            "Validation AUROC increased (-0.519873 --> -0.515190)\n",
            "[2024-05-08 00:22:35,913][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,916][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:35,978][trainers.word2vec_trainer][INFO] - epoch: 141, loss: 0.522\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:36,040][trainers.word2vec_trainer][INFO] - epoch: 142, loss: 0.515\n",
            "Validation AUROC increased (-0.515190 --> -0.514910)\n",
            "[2024-05-08 00:22:36,040][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,043][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,105][trainers.word2vec_trainer][INFO] - epoch: 143, loss: 0.505\n",
            "Validation AUROC increased (-0.514910 --> -0.504886)\n",
            "[2024-05-08 00:22:36,105][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,108][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,175][trainers.word2vec_trainer][INFO] - epoch: 144, loss: 0.502\n",
            "Validation AUROC increased (-0.504886 --> -0.502238)\n",
            "[2024-05-08 00:22:36,175][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,178][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,237][trainers.word2vec_trainer][INFO] - epoch: 145, loss: 0.510\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:36,294][trainers.word2vec_trainer][INFO] - epoch: 146, loss: 0.499\n",
            "Validation AUROC increased (-0.502238 --> -0.499053)\n",
            "[2024-05-08 00:22:36,294][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,297][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,354][trainers.word2vec_trainer][INFO] - epoch: 147, loss: 0.495\n",
            "Validation AUROC increased (-0.499053 --> -0.495429)\n",
            "[2024-05-08 00:22:36,355][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,358][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,416][trainers.word2vec_trainer][INFO] - epoch: 148, loss: 0.489\n",
            "Validation AUROC increased (-0.495429 --> -0.489160)\n",
            "[2024-05-08 00:22:36,417][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,420][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,478][trainers.word2vec_trainer][INFO] - epoch: 149, loss: 0.487\n",
            "Validation AUROC increased (-0.489160 --> -0.486546)\n",
            "[2024-05-08 00:22:36,478][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,481][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,540][trainers.word2vec_trainer][INFO] - epoch: 150, loss: 0.495\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:36,599][trainers.word2vec_trainer][INFO] - epoch: 151, loss: 0.478\n",
            "Validation AUROC increased (-0.486546 --> -0.477668)\n",
            "[2024-05-08 00:22:36,599][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,602][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,661][trainers.word2vec_trainer][INFO] - epoch: 152, loss: 0.483\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:36,721][trainers.word2vec_trainer][INFO] - epoch: 153, loss: 0.480\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:36,786][trainers.word2vec_trainer][INFO] - epoch: 154, loss: 0.473\n",
            "Validation AUROC increased (-0.477668 --> -0.473044)\n",
            "[2024-05-08 00:22:36,786][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,789][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,856][trainers.word2vec_trainer][INFO] - epoch: 155, loss: 0.478\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:36,918][trainers.word2vec_trainer][INFO] - epoch: 156, loss: 0.471\n",
            "Validation AUROC increased (-0.473044 --> -0.470751)\n",
            "[2024-05-08 00:22:36,918][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,922][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,986][trainers.word2vec_trainer][INFO] - epoch: 157, loss: 0.464\n",
            "Validation AUROC increased (-0.470751 --> -0.464420)\n",
            "[2024-05-08 00:22:36,986][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:36,989][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,050][trainers.word2vec_trainer][INFO] - epoch: 158, loss: 0.461\n",
            "Validation AUROC increased (-0.464420 --> -0.460602)\n",
            "[2024-05-08 00:22:37,050][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,052][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,112][trainers.word2vec_trainer][INFO] - epoch: 159, loss: 0.457\n",
            "Validation AUROC increased (-0.460602 --> -0.457305)\n",
            "[2024-05-08 00:22:37,112][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,114][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,186][trainers.word2vec_trainer][INFO] - epoch: 160, loss: 0.453\n",
            "Validation AUROC increased (-0.457305 --> -0.453464)\n",
            "[2024-05-08 00:22:37,186][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,190][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,256][trainers.word2vec_trainer][INFO] - epoch: 161, loss: 0.459\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:37,319][trainers.word2vec_trainer][INFO] - epoch: 162, loss: 0.451\n",
            "Validation AUROC increased (-0.453464 --> -0.450870)\n",
            "[2024-05-08 00:22:37,319][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,322][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,380][trainers.word2vec_trainer][INFO] - epoch: 163, loss: 0.439\n",
            "Validation AUROC increased (-0.450870 --> -0.439053)\n",
            "[2024-05-08 00:22:37,380][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,383][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,444][trainers.word2vec_trainer][INFO] - epoch: 164, loss: 0.437\n",
            "Validation AUROC increased (-0.439053 --> -0.437440)\n",
            "[2024-05-08 00:22:37,444][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,448][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,516][trainers.word2vec_trainer][INFO] - epoch: 165, loss: 0.447\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:37,581][trainers.word2vec_trainer][INFO] - epoch: 166, loss: 0.446\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:37,644][trainers.word2vec_trainer][INFO] - epoch: 167, loss: 0.436\n",
            "Validation AUROC increased (-0.437440 --> -0.436223)\n",
            "[2024-05-08 00:22:37,644][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,647][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,710][trainers.word2vec_trainer][INFO] - epoch: 168, loss: 0.440\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:37,775][trainers.word2vec_trainer][INFO] - epoch: 169, loss: 0.426\n",
            "Validation AUROC increased (-0.436223 --> -0.425810)\n",
            "[2024-05-08 00:22:37,776][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,779][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,850][trainers.word2vec_trainer][INFO] - epoch: 170, loss: 0.438\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:37,910][trainers.word2vec_trainer][INFO] - epoch: 171, loss: 0.421\n",
            "Validation AUROC increased (-0.425810 --> -0.420577)\n",
            "[2024-05-08 00:22:37,910][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,913][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,975][trainers.word2vec_trainer][INFO] - epoch: 172, loss: 0.419\n",
            "Validation AUROC increased (-0.420577 --> -0.419135)\n",
            "[2024-05-08 00:22:37,975][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:37,977][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:38,038][trainers.word2vec_trainer][INFO] - epoch: 173, loss: 0.427\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:38,096][trainers.word2vec_trainer][INFO] - epoch: 174, loss: 0.412\n",
            "Validation AUROC increased (-0.419135 --> -0.412468)\n",
            "[2024-05-08 00:22:38,096][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:38,098][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:38,164][trainers.word2vec_trainer][INFO] - epoch: 175, loss: 0.414\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:38,230][trainers.word2vec_trainer][INFO] - epoch: 176, loss: 0.406\n",
            "Validation AUROC increased (-0.412468 --> -0.406326)\n",
            "[2024-05-08 00:22:38,230][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:38,234][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:38,309][trainers.word2vec_trainer][INFO] - epoch: 177, loss: 0.401\n",
            "Validation AUROC increased (-0.406326 --> -0.401045)\n",
            "[2024-05-08 00:22:38,310][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:38,313][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:38,380][trainers.word2vec_trainer][INFO] - epoch: 178, loss: 0.411\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:38,451][trainers.word2vec_trainer][INFO] - epoch: 179, loss: 0.405\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:38,517][trainers.word2vec_trainer][INFO] - epoch: 180, loss: 0.396\n",
            "Validation AUROC increased (-0.401045 --> -0.396026)\n",
            "[2024-05-08 00:22:38,517][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:38,520][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:38,583][trainers.word2vec_trainer][INFO] - epoch: 181, loss: 0.389\n",
            "Validation AUROC increased (-0.396026 --> -0.389258)\n",
            "[2024-05-08 00:22:38,583][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:38,586][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:38,646][trainers.word2vec_trainer][INFO] - epoch: 182, loss: 0.390\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:38,707][trainers.word2vec_trainer][INFO] - epoch: 183, loss: 0.377\n",
            "Validation AUROC increased (-0.389258 --> -0.377143)\n",
            "[2024-05-08 00:22:38,707][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:38,709][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:38,779][trainers.word2vec_trainer][INFO] - epoch: 184, loss: 0.393\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:38,822][trainers.word2vec_trainer][INFO] - epoch: 185, loss: 0.385\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:38,868][trainers.word2vec_trainer][INFO] - epoch: 186, loss: 0.390\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:38,905][trainers.word2vec_trainer][INFO] - epoch: 187, loss: 0.376\n",
            "Validation AUROC increased (-0.377143 --> -0.375997)\n",
            "[2024-05-08 00:22:38,905][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:38,907][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:38,945][trainers.word2vec_trainer][INFO] - epoch: 188, loss: 0.380\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:38,983][trainers.word2vec_trainer][INFO] - epoch: 189, loss: 0.384\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:39,021][trainers.word2vec_trainer][INFO] - epoch: 190, loss: 0.379\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:39,062][trainers.word2vec_trainer][INFO] - epoch: 191, loss: 0.377\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:39,105][trainers.word2vec_trainer][INFO] - epoch: 192, loss: 0.364\n",
            "Validation AUROC increased (-0.375997 --> -0.363631)\n",
            "[2024-05-08 00:22:39,105][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:39,108][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:39,149][trainers.word2vec_trainer][INFO] - epoch: 193, loss: 0.364\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:39,195][trainers.word2vec_trainer][INFO] - epoch: 194, loss: 0.382\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:39,238][trainers.word2vec_trainer][INFO] - epoch: 195, loss: 0.358\n",
            "Validation AUROC increased (-0.363631 --> -0.358362)\n",
            "[2024-05-08 00:22:39,238][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:39,240][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:39,281][trainers.word2vec_trainer][INFO] - epoch: 196, loss: 0.366\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:39,322][trainers.word2vec_trainer][INFO] - epoch: 197, loss: 0.364\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:39,365][trainers.word2vec_trainer][INFO] - epoch: 198, loss: 0.359\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:39,403][trainers.word2vec_trainer][INFO] - epoch: 199, loss: 0.363\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:39,441][trainers.word2vec_trainer][INFO] - epoch: 200, loss: 0.346\n",
            "Validation AUROC increased (-0.358362 --> -0.346098)\n",
            "[2024-05-08 00:22:39,441][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:39,443][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:39,481][trainers.word2vec_trainer][INFO] - epoch: 201, loss: 0.346\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:39,522][trainers.word2vec_trainer][INFO] - epoch: 202, loss: 0.354\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:39,560][trainers.word2vec_trainer][INFO] - epoch: 203, loss: 0.351\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:39,597][trainers.word2vec_trainer][INFO] - epoch: 204, loss: 0.352\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:39,635][trainers.word2vec_trainer][INFO] - epoch: 205, loss: 0.349\n",
            "EarlyStopping counter: 5 out of 20\n",
            "[2024-05-08 00:22:39,674][trainers.word2vec_trainer][INFO] - epoch: 206, loss: 0.341\n",
            "Validation AUROC increased (-0.346098 --> -0.340814)\n",
            "[2024-05-08 00:22:39,675][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:39,677][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:39,712][trainers.word2vec_trainer][INFO] - epoch: 207, loss: 0.345\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:39,749][trainers.word2vec_trainer][INFO] - epoch: 208, loss: 0.352\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:39,786][trainers.word2vec_trainer][INFO] - epoch: 209, loss: 0.341\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:39,822][trainers.word2vec_trainer][INFO] - epoch: 210, loss: 0.337\n",
            "Validation AUROC increased (-0.340814 --> -0.336605)\n",
            "[2024-05-08 00:22:39,822][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:39,824][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:39,864][trainers.word2vec_trainer][INFO] - epoch: 211, loss: 0.350\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:39,909][trainers.word2vec_trainer][INFO] - epoch: 212, loss: 0.327\n",
            "Validation AUROC increased (-0.336605 --> -0.327149)\n",
            "[2024-05-08 00:22:39,909][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:39,911][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:39,961][trainers.word2vec_trainer][INFO] - epoch: 213, loss: 0.327\n",
            "Validation AUROC increased (-0.327149 --> -0.326858)\n",
            "[2024-05-08 00:22:39,962][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:39,964][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,002][trainers.word2vec_trainer][INFO] - epoch: 214, loss: 0.330\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:40,040][trainers.word2vec_trainer][INFO] - epoch: 215, loss: 0.316\n",
            "Validation AUROC increased (-0.326858 --> -0.316091)\n",
            "[2024-05-08 00:22:40,040][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,042][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,079][trainers.word2vec_trainer][INFO] - epoch: 216, loss: 0.326\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:40,116][trainers.word2vec_trainer][INFO] - epoch: 217, loss: 0.337\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:40,154][trainers.word2vec_trainer][INFO] - epoch: 218, loss: 0.312\n",
            "Validation AUROC increased (-0.316091 --> -0.312443)\n",
            "[2024-05-08 00:22:40,154][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,156][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,198][trainers.word2vec_trainer][INFO] - epoch: 219, loss: 0.301\n",
            "Validation AUROC increased (-0.312443 --> -0.300897)\n",
            "[2024-05-08 00:22:40,198][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,200][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,237][trainers.word2vec_trainer][INFO] - epoch: 220, loss: 0.322\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:40,281][trainers.word2vec_trainer][INFO] - epoch: 221, loss: 0.309\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:40,316][trainers.word2vec_trainer][INFO] - epoch: 222, loss: 0.302\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:40,353][trainers.word2vec_trainer][INFO] - epoch: 223, loss: 0.312\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:40,390][trainers.word2vec_trainer][INFO] - epoch: 224, loss: 0.319\n",
            "EarlyStopping counter: 5 out of 20\n",
            "[2024-05-08 00:22:40,427][trainers.word2vec_trainer][INFO] - epoch: 225, loss: 0.308\n",
            "EarlyStopping counter: 6 out of 20\n",
            "[2024-05-08 00:22:40,463][trainers.word2vec_trainer][INFO] - epoch: 226, loss: 0.302\n",
            "EarlyStopping counter: 7 out of 20\n",
            "[2024-05-08 00:22:40,501][trainers.word2vec_trainer][INFO] - epoch: 227, loss: 0.303\n",
            "EarlyStopping counter: 8 out of 20\n",
            "[2024-05-08 00:22:40,539][trainers.word2vec_trainer][INFO] - epoch: 228, loss: 0.300\n",
            "Validation AUROC increased (-0.300897 --> -0.299964)\n",
            "[2024-05-08 00:22:40,539][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,541][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,586][trainers.word2vec_trainer][INFO] - epoch: 229, loss: 0.293\n",
            "Validation AUROC increased (-0.299964 --> -0.292966)\n",
            "[2024-05-08 00:22:40,586][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,588][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,624][trainers.word2vec_trainer][INFO] - epoch: 230, loss: 0.292\n",
            "Validation AUROC increased (-0.292966 --> -0.292116)\n",
            "[2024-05-08 00:22:40,624][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,626][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,662][trainers.word2vec_trainer][INFO] - epoch: 231, loss: 0.312\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:40,699][trainers.word2vec_trainer][INFO] - epoch: 232, loss: 0.294\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:40,738][trainers.word2vec_trainer][INFO] - epoch: 233, loss: 0.303\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:40,777][trainers.word2vec_trainer][INFO] - epoch: 234, loss: 0.289\n",
            "Validation AUROC increased (-0.292116 --> -0.289110)\n",
            "[2024-05-08 00:22:40,777][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,779][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,816][trainers.word2vec_trainer][INFO] - epoch: 235, loss: 0.291\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:40,856][trainers.word2vec_trainer][INFO] - epoch: 236, loss: 0.308\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:40,897][trainers.word2vec_trainer][INFO] - epoch: 237, loss: 0.285\n",
            "Validation AUROC increased (-0.289110 --> -0.285232)\n",
            "[2024-05-08 00:22:40,897][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,900][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,943][trainers.word2vec_trainer][INFO] - epoch: 238, loss: 0.288\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:40,980][trainers.word2vec_trainer][INFO] - epoch: 239, loss: 0.281\n",
            "Validation AUROC increased (-0.285232 --> -0.281292)\n",
            "[2024-05-08 00:22:40,980][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:40,982][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,020][trainers.word2vec_trainer][INFO] - epoch: 240, loss: 0.283\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:41,058][trainers.word2vec_trainer][INFO] - epoch: 241, loss: 0.277\n",
            "Validation AUROC increased (-0.281292 --> -0.276687)\n",
            "[2024-05-08 00:22:41,058][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,060][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,097][trainers.word2vec_trainer][INFO] - epoch: 242, loss: 0.276\n",
            "Validation AUROC increased (-0.276687 --> -0.276160)\n",
            "[2024-05-08 00:22:41,097][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,099][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,137][trainers.word2vec_trainer][INFO] - epoch: 243, loss: 0.281\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:41,188][trainers.word2vec_trainer][INFO] - epoch: 244, loss: 0.272\n",
            "Validation AUROC increased (-0.276160 --> -0.272114)\n",
            "[2024-05-08 00:22:41,188][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,191][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,235][trainers.word2vec_trainer][INFO] - epoch: 245, loss: 0.277\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:41,272][trainers.word2vec_trainer][INFO] - epoch: 246, loss: 0.284\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:41,308][trainers.word2vec_trainer][INFO] - epoch: 247, loss: 0.267\n",
            "Validation AUROC increased (-0.272114 --> -0.267092)\n",
            "[2024-05-08 00:22:41,308][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,310][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,346][trainers.word2vec_trainer][INFO] - epoch: 248, loss: 0.263\n",
            "Validation AUROC increased (-0.267092 --> -0.263275)\n",
            "[2024-05-08 00:22:41,346][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,348][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,384][trainers.word2vec_trainer][INFO] - epoch: 249, loss: 0.265\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:41,421][trainers.word2vec_trainer][INFO] - epoch: 250, loss: 0.275\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:41,462][trainers.word2vec_trainer][INFO] - epoch: 251, loss: 0.270\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:41,502][trainers.word2vec_trainer][INFO] - epoch: 252, loss: 0.279\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:41,544][trainers.word2vec_trainer][INFO] - epoch: 253, loss: 0.265\n",
            "EarlyStopping counter: 5 out of 20\n",
            "[2024-05-08 00:22:41,581][trainers.word2vec_trainer][INFO] - epoch: 254, loss: 0.260\n",
            "Validation AUROC increased (-0.263275 --> -0.259720)\n",
            "[2024-05-08 00:22:41,582][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,584][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,620][trainers.word2vec_trainer][INFO] - epoch: 255, loss: 0.254\n",
            "Validation AUROC increased (-0.259720 --> -0.253978)\n",
            "[2024-05-08 00:22:41,621][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,622][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,660][trainers.word2vec_trainer][INFO] - epoch: 256, loss: 0.256\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:41,696][trainers.word2vec_trainer][INFO] - epoch: 257, loss: 0.271\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:41,735][trainers.word2vec_trainer][INFO] - epoch: 258, loss: 0.265\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:41,775][trainers.word2vec_trainer][INFO] - epoch: 259, loss: 0.266\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:41,811][trainers.word2vec_trainer][INFO] - epoch: 260, loss: 0.247\n",
            "Validation AUROC increased (-0.253978 --> -0.246742)\n",
            "[2024-05-08 00:22:41,811][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,813][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:41,854][trainers.word2vec_trainer][INFO] - epoch: 261, loss: 0.251\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:41,889][trainers.word2vec_trainer][INFO] - epoch: 262, loss: 0.268\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:41,935][trainers.word2vec_trainer][INFO] - epoch: 263, loss: 0.272\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:41,972][trainers.word2vec_trainer][INFO] - epoch: 264, loss: 0.251\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:42,009][trainers.word2vec_trainer][INFO] - epoch: 265, loss: 0.253\n",
            "EarlyStopping counter: 5 out of 20\n",
            "[2024-05-08 00:22:42,048][trainers.word2vec_trainer][INFO] - epoch: 266, loss: 0.254\n",
            "EarlyStopping counter: 6 out of 20\n",
            "[2024-05-08 00:22:42,089][trainers.word2vec_trainer][INFO] - epoch: 267, loss: 0.249\n",
            "EarlyStopping counter: 7 out of 20\n",
            "[2024-05-08 00:22:42,126][trainers.word2vec_trainer][INFO] - epoch: 268, loss: 0.253\n",
            "EarlyStopping counter: 8 out of 20\n",
            "[2024-05-08 00:22:42,164][trainers.word2vec_trainer][INFO] - epoch: 269, loss: 0.251\n",
            "EarlyStopping counter: 9 out of 20\n",
            "[2024-05-08 00:22:42,205][trainers.word2vec_trainer][INFO] - epoch: 270, loss: 0.261\n",
            "EarlyStopping counter: 10 out of 20\n",
            "[2024-05-08 00:22:42,242][trainers.word2vec_trainer][INFO] - epoch: 271, loss: 0.232\n",
            "Validation AUROC increased (-0.246742 --> -0.231696)\n",
            "[2024-05-08 00:22:42,243][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:42,244][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:42,282][trainers.word2vec_trainer][INFO] - epoch: 272, loss: 0.232\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:42,319][trainers.word2vec_trainer][INFO] - epoch: 273, loss: 0.245\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:42,359][trainers.word2vec_trainer][INFO] - epoch: 274, loss: 0.242\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:42,397][trainers.word2vec_trainer][INFO] - epoch: 275, loss: 0.245\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:42,435][trainers.word2vec_trainer][INFO] - epoch: 276, loss: 0.241\n",
            "EarlyStopping counter: 5 out of 20\n",
            "[2024-05-08 00:22:42,472][trainers.word2vec_trainer][INFO] - epoch: 277, loss: 0.242\n",
            "EarlyStopping counter: 6 out of 20\n",
            "[2024-05-08 00:22:42,509][trainers.word2vec_trainer][INFO] - epoch: 278, loss: 0.242\n",
            "EarlyStopping counter: 7 out of 20\n",
            "[2024-05-08 00:22:42,547][trainers.word2vec_trainer][INFO] - epoch: 279, loss: 0.246\n",
            "EarlyStopping counter: 8 out of 20\n",
            "[2024-05-08 00:22:42,585][trainers.word2vec_trainer][INFO] - epoch: 280, loss: 0.237\n",
            "EarlyStopping counter: 9 out of 20\n",
            "[2024-05-08 00:22:42,622][trainers.word2vec_trainer][INFO] - epoch: 281, loss: 0.238\n",
            "EarlyStopping counter: 10 out of 20\n",
            "[2024-05-08 00:22:42,662][trainers.word2vec_trainer][INFO] - epoch: 282, loss: 0.240\n",
            "EarlyStopping counter: 11 out of 20\n",
            "[2024-05-08 00:22:42,699][trainers.word2vec_trainer][INFO] - epoch: 283, loss: 0.240\n",
            "EarlyStopping counter: 12 out of 20\n",
            "[2024-05-08 00:22:42,736][trainers.word2vec_trainer][INFO] - epoch: 284, loss: 0.219\n",
            "Validation AUROC increased (-0.231696 --> -0.218542)\n",
            "[2024-05-08 00:22:42,736][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:42,738][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:42,777][trainers.word2vec_trainer][INFO] - epoch: 285, loss: 0.233\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:42,818][trainers.word2vec_trainer][INFO] - epoch: 286, loss: 0.231\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:42,857][trainers.word2vec_trainer][INFO] - epoch: 287, loss: 0.221\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:42,895][trainers.word2vec_trainer][INFO] - epoch: 288, loss: 0.227\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:42,933][trainers.word2vec_trainer][INFO] - epoch: 289, loss: 0.226\n",
            "EarlyStopping counter: 5 out of 20\n",
            "[2024-05-08 00:22:42,985][trainers.word2vec_trainer][INFO] - epoch: 290, loss: 0.232\n",
            "EarlyStopping counter: 6 out of 20\n",
            "[2024-05-08 00:22:43,023][trainers.word2vec_trainer][INFO] - epoch: 291, loss: 0.217\n",
            "Validation AUROC increased (-0.218542 --> -0.216776)\n",
            "[2024-05-08 00:22:43,023][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:43,025][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:43,064][trainers.word2vec_trainer][INFO] - epoch: 292, loss: 0.210\n",
            "Validation AUROC increased (-0.216776 --> -0.210292)\n",
            "[2024-05-08 00:22:43,064][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:43,066][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:43,103][trainers.word2vec_trainer][INFO] - epoch: 293, loss: 0.222\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:43,140][trainers.word2vec_trainer][INFO] - epoch: 294, loss: 0.236\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:43,179][trainers.word2vec_trainer][INFO] - epoch: 295, loss: 0.218\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:43,220][trainers.word2vec_trainer][INFO] - epoch: 296, loss: 0.220\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:43,261][trainers.word2vec_trainer][INFO] - epoch: 297, loss: 0.222\n",
            "EarlyStopping counter: 5 out of 20\n",
            "[2024-05-08 00:22:43,301][trainers.word2vec_trainer][INFO] - epoch: 298, loss: 0.220\n",
            "EarlyStopping counter: 6 out of 20\n",
            "[2024-05-08 00:22:43,338][trainers.word2vec_trainer][INFO] - epoch: 299, loss: 0.220\n",
            "EarlyStopping counter: 7 out of 20\n",
            "[2024-05-08 00:22:43,375][trainers.word2vec_trainer][INFO] - epoch: 300, loss: 0.209\n",
            "Validation AUROC increased (-0.210292 --> -0.209279)\n",
            "[2024-05-08 00:22:43,375][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:43,377][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:43,415][trainers.word2vec_trainer][INFO] - epoch: 301, loss: 0.220\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:43,452][trainers.word2vec_trainer][INFO] - epoch: 302, loss: 0.225\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:43,489][trainers.word2vec_trainer][INFO] - epoch: 303, loss: 0.225\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:43,526][trainers.word2vec_trainer][INFO] - epoch: 304, loss: 0.212\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:43,567][trainers.word2vec_trainer][INFO] - epoch: 305, loss: 0.218\n",
            "EarlyStopping counter: 5 out of 20\n",
            "[2024-05-08 00:22:43,606][trainers.word2vec_trainer][INFO] - epoch: 306, loss: 0.221\n",
            "EarlyStopping counter: 6 out of 20\n",
            "[2024-05-08 00:22:43,644][trainers.word2vec_trainer][INFO] - epoch: 307, loss: 0.226\n",
            "EarlyStopping counter: 7 out of 20\n",
            "[2024-05-08 00:22:43,681][trainers.word2vec_trainer][INFO] - epoch: 308, loss: 0.220\n",
            "EarlyStopping counter: 8 out of 20\n",
            "[2024-05-08 00:22:43,717][trainers.word2vec_trainer][INFO] - epoch: 309, loss: 0.217\n",
            "EarlyStopping counter: 9 out of 20\n",
            "[2024-05-08 00:22:43,753][trainers.word2vec_trainer][INFO] - epoch: 310, loss: 0.221\n",
            "EarlyStopping counter: 10 out of 20\n",
            "[2024-05-08 00:22:43,792][trainers.word2vec_trainer][INFO] - epoch: 311, loss: 0.209\n",
            "EarlyStopping counter: 11 out of 20\n",
            "[2024-05-08 00:22:43,829][trainers.word2vec_trainer][INFO] - epoch: 312, loss: 0.216\n",
            "EarlyStopping counter: 12 out of 20\n",
            "[2024-05-08 00:22:43,871][trainers.word2vec_trainer][INFO] - epoch: 313, loss: 0.202\n",
            "Validation AUROC increased (-0.209279 --> -0.201880)\n",
            "[2024-05-08 00:22:43,871][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:43,873][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:43,912][trainers.word2vec_trainer][INFO] - epoch: 314, loss: 0.210\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:43,953][trainers.word2vec_trainer][INFO] - epoch: 315, loss: 0.217\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:44,005][trainers.word2vec_trainer][INFO] - epoch: 316, loss: 0.210\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:44,045][trainers.word2vec_trainer][INFO] - epoch: 317, loss: 0.210\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:44,084][trainers.word2vec_trainer][INFO] - epoch: 318, loss: 0.212\n",
            "EarlyStopping counter: 5 out of 20\n",
            "[2024-05-08 00:22:44,122][trainers.word2vec_trainer][INFO] - epoch: 319, loss: 0.221\n",
            "EarlyStopping counter: 6 out of 20\n",
            "[2024-05-08 00:22:44,165][trainers.word2vec_trainer][INFO] - epoch: 320, loss: 0.203\n",
            "EarlyStopping counter: 7 out of 20\n",
            "[2024-05-08 00:22:44,209][trainers.word2vec_trainer][INFO] - epoch: 321, loss: 0.208\n",
            "EarlyStopping counter: 8 out of 20\n",
            "[2024-05-08 00:22:44,252][trainers.word2vec_trainer][INFO] - epoch: 322, loss: 0.198\n",
            "Validation AUROC increased (-0.201880 --> -0.198138)\n",
            "[2024-05-08 00:22:44,252][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:44,254][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:44,296][trainers.word2vec_trainer][INFO] - epoch: 323, loss: 0.199\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:44,335][trainers.word2vec_trainer][INFO] - epoch: 324, loss: 0.191\n",
            "Validation AUROC increased (-0.198138 --> -0.191027)\n",
            "[2024-05-08 00:22:44,336][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:44,337][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:44,375][trainers.word2vec_trainer][INFO] - epoch: 325, loss: 0.201\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:44,413][trainers.word2vec_trainer][INFO] - epoch: 326, loss: 0.213\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:44,455][trainers.word2vec_trainer][INFO] - epoch: 327, loss: 0.205\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:44,498][trainers.word2vec_trainer][INFO] - epoch: 328, loss: 0.204\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:44,537][trainers.word2vec_trainer][INFO] - epoch: 329, loss: 0.197\n",
            "EarlyStopping counter: 5 out of 20\n",
            "[2024-05-08 00:22:44,577][trainers.word2vec_trainer][INFO] - epoch: 330, loss: 0.190\n",
            "Validation AUROC increased (-0.191027 --> -0.190434)\n",
            "[2024-05-08 00:22:44,577][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:44,579][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:44,619][trainers.word2vec_trainer][INFO] - epoch: 331, loss: 0.194\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:44,659][trainers.word2vec_trainer][INFO] - epoch: 332, loss: 0.205\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:44,700][trainers.word2vec_trainer][INFO] - epoch: 333, loss: 0.200\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:44,739][trainers.word2vec_trainer][INFO] - epoch: 334, loss: 0.212\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:44,785][trainers.word2vec_trainer][INFO] - epoch: 335, loss: 0.198\n",
            "EarlyStopping counter: 5 out of 20\n",
            "[2024-05-08 00:22:44,824][trainers.word2vec_trainer][INFO] - epoch: 336, loss: 0.193\n",
            "EarlyStopping counter: 6 out of 20\n",
            "[2024-05-08 00:22:44,864][trainers.word2vec_trainer][INFO] - epoch: 337, loss: 0.186\n",
            "Validation AUROC increased (-0.190434 --> -0.186043)\n",
            "[2024-05-08 00:22:44,865][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:44,867][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:44,906][trainers.word2vec_trainer][INFO] - epoch: 338, loss: 0.199\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:44,946][trainers.word2vec_trainer][INFO] - epoch: 339, loss: 0.182\n",
            "Validation AUROC increased (-0.186043 --> -0.182263)\n",
            "[2024-05-08 00:22:44,946][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:44,948][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:44,987][trainers.word2vec_trainer][INFO] - epoch: 340, loss: 0.183\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:45,034][trainers.word2vec_trainer][INFO] - epoch: 341, loss: 0.182\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:45,074][trainers.word2vec_trainer][INFO] - epoch: 342, loss: 0.198\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:45,111][trainers.word2vec_trainer][INFO] - epoch: 343, loss: 0.190\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:45,149][trainers.word2vec_trainer][INFO] - epoch: 344, loss: 0.211\n",
            "EarlyStopping counter: 5 out of 20\n",
            "[2024-05-08 00:22:45,188][trainers.word2vec_trainer][INFO] - epoch: 345, loss: 0.202\n",
            "EarlyStopping counter: 6 out of 20\n",
            "[2024-05-08 00:22:45,236][trainers.word2vec_trainer][INFO] - epoch: 346, loss: 0.185\n",
            "EarlyStopping counter: 7 out of 20\n",
            "[2024-05-08 00:22:45,279][trainers.word2vec_trainer][INFO] - epoch: 347, loss: 0.189\n",
            "EarlyStopping counter: 8 out of 20\n",
            "[2024-05-08 00:22:45,316][trainers.word2vec_trainer][INFO] - epoch: 348, loss: 0.193\n",
            "EarlyStopping counter: 9 out of 20\n",
            "[2024-05-08 00:22:45,353][trainers.word2vec_trainer][INFO] - epoch: 349, loss: 0.189\n",
            "EarlyStopping counter: 10 out of 20\n",
            "[2024-05-08 00:22:45,392][trainers.word2vec_trainer][INFO] - epoch: 350, loss: 0.193\n",
            "EarlyStopping counter: 11 out of 20\n",
            "[2024-05-08 00:22:45,430][trainers.word2vec_trainer][INFO] - epoch: 351, loss: 0.176\n",
            "Validation AUROC increased (-0.182263 --> -0.175781)\n",
            "[2024-05-08 00:22:45,430][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:45,432][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:45,471][trainers.word2vec_trainer][INFO] - epoch: 352, loss: 0.189\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:45,509][trainers.word2vec_trainer][INFO] - epoch: 353, loss: 0.183\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:45,548][trainers.word2vec_trainer][INFO] - epoch: 354, loss: 0.183\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:45,592][trainers.word2vec_trainer][INFO] - epoch: 355, loss: 0.192\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:45,633][trainers.word2vec_trainer][INFO] - epoch: 356, loss: 0.181\n",
            "EarlyStopping counter: 5 out of 20\n",
            "[2024-05-08 00:22:45,672][trainers.word2vec_trainer][INFO] - epoch: 357, loss: 0.183\n",
            "EarlyStopping counter: 6 out of 20\n",
            "[2024-05-08 00:22:45,710][trainers.word2vec_trainer][INFO] - epoch: 358, loss: 0.203\n",
            "EarlyStopping counter: 7 out of 20\n",
            "[2024-05-08 00:22:45,749][trainers.word2vec_trainer][INFO] - epoch: 359, loss: 0.188\n",
            "EarlyStopping counter: 8 out of 20\n",
            "[2024-05-08 00:22:45,787][trainers.word2vec_trainer][INFO] - epoch: 360, loss: 0.180\n",
            "EarlyStopping counter: 9 out of 20\n",
            "[2024-05-08 00:22:45,826][trainers.word2vec_trainer][INFO] - epoch: 361, loss: 0.181\n",
            "EarlyStopping counter: 10 out of 20\n",
            "[2024-05-08 00:22:45,865][trainers.word2vec_trainer][INFO] - epoch: 362, loss: 0.185\n",
            "EarlyStopping counter: 11 out of 20\n",
            "[2024-05-08 00:22:45,909][trainers.word2vec_trainer][INFO] - epoch: 363, loss: 0.189\n",
            "EarlyStopping counter: 12 out of 20\n",
            "[2024-05-08 00:22:45,950][trainers.word2vec_trainer][INFO] - epoch: 364, loss: 0.162\n",
            "Validation AUROC increased (-0.175781 --> -0.161844)\n",
            "[2024-05-08 00:22:45,950][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:45,952][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:45,990][trainers.word2vec_trainer][INFO] - epoch: 365, loss: 0.156\n",
            "Validation AUROC increased (-0.161844 --> -0.156416)\n",
            "[2024-05-08 00:22:45,990][trainers.word2vec_trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:45,992][trainers.word2vec_trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 00:22:46,037][trainers.word2vec_trainer][INFO] - epoch: 366, loss: 0.189\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[2024-05-08 00:22:46,077][trainers.word2vec_trainer][INFO] - epoch: 367, loss: 0.181\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[2024-05-08 00:22:46,118][trainers.word2vec_trainer][INFO] - epoch: 368, loss: 0.160\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[2024-05-08 00:22:46,155][trainers.word2vec_trainer][INFO] - epoch: 369, loss: 0.175\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[2024-05-08 00:22:46,201][trainers.word2vec_trainer][INFO] - epoch: 370, loss: 0.169\n",
            "EarlyStopping counter: 5 out of 20\n",
            "[2024-05-08 00:22:46,239][trainers.word2vec_trainer][INFO] - epoch: 371, loss: 0.174\n",
            "EarlyStopping counter: 6 out of 20\n",
            "[2024-05-08 00:22:46,277][trainers.word2vec_trainer][INFO] - epoch: 372, loss: 0.184\n",
            "EarlyStopping counter: 7 out of 20\n",
            "[2024-05-08 00:22:46,316][trainers.word2vec_trainer][INFO] - epoch: 373, loss: 0.174\n",
            "EarlyStopping counter: 8 out of 20\n",
            "[2024-05-08 00:22:46,354][trainers.word2vec_trainer][INFO] - epoch: 374, loss: 0.167\n",
            "EarlyStopping counter: 9 out of 20\n",
            "[2024-05-08 00:22:46,395][trainers.word2vec_trainer][INFO] - epoch: 375, loss: 0.166\n",
            "EarlyStopping counter: 10 out of 20\n",
            "[2024-05-08 00:22:46,433][trainers.word2vec_trainer][INFO] - epoch: 376, loss: 0.163\n",
            "EarlyStopping counter: 11 out of 20\n",
            "[2024-05-08 00:22:46,471][trainers.word2vec_trainer][INFO] - epoch: 377, loss: 0.185\n",
            "EarlyStopping counter: 12 out of 20\n",
            "[2024-05-08 00:22:46,508][trainers.word2vec_trainer][INFO] - epoch: 378, loss: 0.187\n",
            "EarlyStopping counter: 13 out of 20\n",
            "[2024-05-08 00:22:46,546][trainers.word2vec_trainer][INFO] - epoch: 379, loss: 0.184\n",
            "EarlyStopping counter: 14 out of 20\n",
            "[2024-05-08 00:22:46,583][trainers.word2vec_trainer][INFO] - epoch: 380, loss: 0.169\n",
            "EarlyStopping counter: 15 out of 20\n",
            "[2024-05-08 00:22:46,620][trainers.word2vec_trainer][INFO] - epoch: 381, loss: 0.177\n",
            "EarlyStopping counter: 16 out of 20\n",
            "[2024-05-08 00:22:46,656][trainers.word2vec_trainer][INFO] - epoch: 382, loss: 0.163\n",
            "EarlyStopping counter: 17 out of 20\n",
            "[2024-05-08 00:22:46,696][trainers.word2vec_trainer][INFO] - epoch: 383, loss: 0.173\n",
            "EarlyStopping counter: 18 out of 20\n",
            "[2024-05-08 00:22:46,736][trainers.word2vec_trainer][INFO] - epoch: 384, loss: 0.169\n",
            "EarlyStopping counter: 19 out of 20\n",
            "[2024-05-08 00:22:46,773][trainers.word2vec_trainer][INFO] - epoch: 385, loss: 0.179\n",
            "EarlyStopping counter: 20 out of 20\n",
            "[2024-05-08 00:22:46,773][__main__][INFO] - done training\n"
          ]
        }
      ],
      "source": [
        "!python main.py \\\n",
        "    --distributed_world_size 1 \\\n",
        "    --input_path '/content/cs598_descemb_project/datasets/data_output_path' \\\n",
        "    --src_data 'eicu' \\\n",
        "    --task 'w2v' \\\n",
        "    --model 'codeemb'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d564e8fa-f54d-4caf-be33-2c626eefbb5e",
      "metadata": {
        "id": "d564e8fa-f54d-4caf-be33-2c626eefbb5e"
      },
      "source": [
        "**Note**\n",
        "\n",
        "- `data` should be set to `mimiciii` or `eicu`\n",
        "- `percent` should be set to probability (default: `0.3`) of masking for MLM\n",
        "- `model` should be set to `descemb_bert` or `descemb_rnn`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b52dcbd7-9c64-4b7e-9eb0-cda8d9e97323",
      "metadata": {
        "id": "b52dcbd7-9c64-4b7e-9eb0-cda8d9e97323"
      },
      "source": [
        "## Training\n",
        "\n",
        "### Computational Requirements\n",
        "The computational requirements for training the DescEmb model, based on the information from the README.md and the paper, include:\n",
        "\n",
        "- **Processor**: Training is computationally intensive and recommended to be performed on a system with at least 128 cores of an AMD EPYC 7502 32-Core Processor for efficient processing.\n",
        "- **Memory**: At least 60GB of RAM is required due to the large size of the datasets and the complexity of the model architectures involved.\n",
        "- **Software**: Python 3.7 or higher with PyTorch 1.8.1 or higher is required. Make sure all dependencies from the `environment.yml` are installed.\n",
        "\n",
        "These requirements ensure that the model training can proceed without hardware-induced limitations, particularly for this task, which involves large datasets like MIMIC-III and eICU.\n",
        "\n",
        "### Implementation Code\n",
        "\n",
        "Below are Python code snippets that demonstrate how to train and fine-tune the models using PyTorch. These examples are based on the commands found in the README.md:\n",
        "\n",
        "#### Training a New Model\n",
        "\n",
        "Other configurations will set to be default, which were used in the DescEmb paper.\n",
        "\n",
        "`$descemb` should be 'descemb_bert' or 'descemb_rnn'\n",
        "\n",
        "`$ratio` should be set to one of [10, 30, 50, 70, 100] (default: 100)\n",
        "\n",
        "`$value` should be set to one of ['NV', 'VA', 'DSVA', 'DSVA_DPE', 'VC']\n",
        "\n",
        "`$task` should be set to one of ['readmission', 'mortality', 'los_3day', 'los_7day', 'diagnosis']\n",
        "\n",
        "Note that `--input-path ` should be the root directory containing preprocessed data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af6797e4-8738-4f94-9828-f7848690fde4",
      "metadata": {
        "id": "af6797e4-8738-4f94-9828-f7848690fde4"
      },
      "source": [
        "##### Training a New CodeEmb Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "cd426595-77d0-498d-bf93-177003d1782f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd426595-77d0-498d-bf93-177003d1782f",
        "outputId": "6242a449-d333-422a-8f56-d342d8a26af6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-05-08 01:17:05 | INFO numexpr.utils NumExpr defaulting to 2 threads.)))\n",
            "[2024-05-08 01:17:06,651][trainers.trainer][INFO] - {'batch_size': 128,\n",
            " 'bert_model': 'bert_tiny',\n",
            " 'device_ids': [0],\n",
            " 'disable_validation': False,\n",
            " 'distributed_world_size': 1,\n",
            " 'dropout': 0.3,\n",
            " 'embed_model': 'codeemb',\n",
            " 'enc_embed_dim': 128,\n",
            " 'enc_hidden_dim': 256,\n",
            " 'eval_data': None,\n",
            " 'fold': None,\n",
            " 'init_bert_params': False,\n",
            " 'init_bert_params_with_freeze': False,\n",
            " 'input_path': '/content/cs598_descemb_project/datasets/data_output_path',\n",
            " 'load_pretrained_weights': False,\n",
            " 'lr': 0.0001,\n",
            " 'max_event_len': 150,\n",
            " 'mlm_prob': 0.3,\n",
            " 'model': 'ehr_model',\n",
            " 'model_path': None,\n",
            " 'n_epochs': 1000,\n",
            " 'patience': 5,\n",
            " 'pred_embed_dim': 128,\n",
            " 'pred_hidden_dim': 256,\n",
            " 'pred_model': 'rnn',\n",
            " 'ratio': '70',\n",
            " 'rnn_layer': 1,\n",
            " 'save_dir': 'checkpoints',\n",
            " 'save_prefix': 'checkpoint',\n",
            " 'seed': 1,\n",
            " 'src_data': 'eicu',\n",
            " 'task': 'readmission',\n",
            " 'transfer': False,\n",
            " 'valid_subsets': ['valid', 'test'],\n",
            " 'value_mode': 'DSVA'}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "[2024-05-08 01:17:06,662][trainers.trainer][INFO] - EHRModel(\n",
            "  (embed_model): CodeEmb(\n",
            "    (embedding): Embedding(5054, 128, padding_idx=0)\n",
            "  )\n",
            "  (pred_model): RNNModel(\n",
            "    (model): GRU(128, 256, batch_first=True, dropout=0.3)\n",
            "    (final_proj): Linear(in_features=256, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "[2024-05-08 01:17:06,662][trainers.trainer][INFO] - task: readmission\n",
            "[2024-05-08 01:17:06,662][trainers.trainer][INFO] - model: EHRModel\n",
            "[2024-05-08 01:17:06,662][trainers.trainer][INFO] - num. model params: 943,617 (num. trained: 943,617)\n",
            "[2024-05-08 01:17:07,952][datasets.dataset][INFO] - loaded 13 train samples\n",
            "[2024-05-08 01:17:09,000][datasets.dataset][INFO] - loaded 4 valid samples\n",
            "[2024-05-08 01:17:10,324][datasets.dataset][INFO] - loaded 16 test samples\n",
            "[2024-05-08 01:17:10,981][trainers.trainer][INFO] - begin training epoch 1\n",
            "100% 1/1 [00:00<00:00,  1.15it/s]\n",
            "[2024-05-08 01:17:11,852][train][INFO] - epoch: 1, loss: 0.618, auroc: 0.417, auprc: 0.125\n",
            "[2024-05-08 01:17:11,853][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:17:11,863][valid][INFO] - epoch: 1, loss: 0.695, auroc: 0.000, auprc: 0.250\n",
            "[2024-05-08 01:17:11,863][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:17:11,874][test][INFO] - epoch: 1, loss: 1.274, auroc: 0.778, auprc: 0.600\n",
            "[2024-05-08 01:17:11,874][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:17:11,896][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:17:11,896][trainers.trainer][INFO] - begin training epoch 2\n",
            "100% 1/1 [00:00<00:00, 60.63it/s]\n",
            "[2024-05-08 01:17:11,915][train][INFO] - epoch: 2, loss: 0.605, auroc: 0.417, auprc: 0.125\n",
            "[2024-05-08 01:17:11,915][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:17:11,925][valid][INFO] - epoch: 2, loss: 0.696, auroc: 0.000, auprc: 0.250\n",
            "[2024-05-08 01:17:11,925][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:17:11,935][test][INFO] - epoch: 2, loss: 1.265, auroc: 0.778, auprc: 0.600\n",
            "[2024-05-08 01:17:11,935][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:17:11,965][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:17:11,965][trainers.trainer][INFO] - begin training epoch 3\n",
            "100% 1/1 [00:00<00:00, 53.16it/s]\n",
            "[2024-05-08 01:17:11,986][train][INFO] - epoch: 3, loss: 0.593, auroc: 0.417, auprc: 0.125\n",
            "[2024-05-08 01:17:11,987][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:17:11,997][valid][INFO] - epoch: 3, loss: 0.696, auroc: 0.000, auprc: 0.250\n",
            "[2024-05-08 01:17:11,998][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:17:12,008][test][INFO] - epoch: 3, loss: 1.258, auroc: 0.778, auprc: 0.600\n",
            "[2024-05-08 01:17:12,008][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:17:12,032][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:17:12,032][trainers.trainer][INFO] - begin training epoch 4\n",
            "100% 1/1 [00:00<00:00, 57.07it/s]\n",
            "[2024-05-08 01:17:12,052][train][INFO] - epoch: 4, loss: 0.583, auroc: 0.417, auprc: 0.125\n",
            "[2024-05-08 01:17:12,052][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:17:12,062][valid][INFO] - epoch: 4, loss: 0.696, auroc: 0.000, auprc: 0.250\n",
            "[2024-05-08 01:17:12,062][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:17:12,072][test][INFO] - epoch: 4, loss: 1.251, auroc: 0.778, auprc: 0.600\n",
            "[2024-05-08 01:17:12,072][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:17:12,094][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:17:12,094][trainers.trainer][INFO] - begin training epoch 5\n",
            "100% 1/1 [00:00<00:00, 54.31it/s]\n",
            "[2024-05-08 01:17:12,115][train][INFO] - epoch: 5, loss: 0.573, auroc: 0.417, auprc: 0.125\n",
            "[2024-05-08 01:17:12,115][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:17:12,125][valid][INFO] - epoch: 5, loss: 0.697, auroc: 0.000, auprc: 0.250\n",
            "[2024-05-08 01:17:12,125][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:17:12,136][test][INFO] - epoch: 5, loss: 1.244, auroc: 0.778, auprc: 0.600\n",
            "[2024-05-08 01:17:12,136][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:17:12,160][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:17:12,160][trainers.trainer][INFO] - begin training epoch 6\n",
            "100% 1/1 [00:00<00:00, 51.97it/s]\n",
            "[2024-05-08 01:17:12,182][train][INFO] - epoch: 6, loss: 0.564, auroc: 0.417, auprc: 0.125\n",
            "[2024-05-08 01:17:12,182][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:17:12,192][valid][INFO] - epoch: 6, loss: 0.698, auroc: 0.000, auprc: 0.250\n",
            "[2024-05-08 01:17:12,193][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:17:12,203][test][INFO] - epoch: 6, loss: 1.239, auroc: 0.778, auprc: 0.600\n",
            "[2024-05-08 01:17:12,203][utils.trainer_utils][INFO] - early stop since valid performance hasn't improved for last 5 runs\n",
            "[2024-05-08 01:17:12,203][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:17:12,224][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:17:12,224][__main__][INFO] - done training\n"
          ]
        }
      ],
      "source": [
        "# Example training new DescEmb model:\n",
        "# train_new_codeemb_model('data_output_path/mimic', 'mimic', 'readmission', 100, 'DSVA')\n",
        "# train_new_codeemb_model('data_output_path/eicu', 'eicu', 'mortality', 70, 'VA')\n",
        "\n",
        "!python main.py \\\n",
        "    --distributed_world_size 1 \\\n",
        "    --input_path '/content/cs598_descemb_project/datasets/data_output_path' \\\n",
        "    --model 'ehr_model' \\\n",
        "    --embed_model 'codeemb' \\\n",
        "    --pred_model 'rnn' \\\n",
        "    --src_data 'eicu' \\\n",
        "    --ratio 70 \\\n",
        "    --value_mode DSVA \\\n",
        "    --task 'readmission'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94dd4f4a-955c-42e4-86ae-3442528942fd",
      "metadata": {
        "id": "94dd4f4a-955c-42e4-86ae-3442528942fd"
      },
      "source": [
        "##### Training a New DescEmb Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "e45ed9f9-62bc-4abf-8b19-fc524b12cb3c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e45ed9f9-62bc-4abf-8b19-fc524b12cb3c",
        "outputId": "68916005-e563-47c2-ad68-2f6337cb67e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-05-08 01:28:04 | INFO numexpr.utils NumExpr defaulting to 2 threads.)))\n",
            "[2024-05-08 01:28:05,449][trainers.trainer][INFO] - {'batch_size': 128,\n",
            " 'bert_model': 'bert_tiny',\n",
            " 'device_ids': [0],\n",
            " 'disable_validation': False,\n",
            " 'distributed_world_size': 1,\n",
            " 'dropout': 0.3,\n",
            " 'embed_model': 'descemb_bert',\n",
            " 'enc_embed_dim': 128,\n",
            " 'enc_hidden_dim': 256,\n",
            " 'eval_data': None,\n",
            " 'fold': None,\n",
            " 'init_bert_params': False,\n",
            " 'init_bert_params_with_freeze': False,\n",
            " 'input_path': '/content/cs598_descemb_project/datasets/data_output_path',\n",
            " 'load_pretrained_weights': False,\n",
            " 'lr': 0.0001,\n",
            " 'max_event_len': 150,\n",
            " 'mlm_prob': 0.3,\n",
            " 'model': 'ehr_model',\n",
            " 'model_path': None,\n",
            " 'n_epochs': 1000,\n",
            " 'patience': 5,\n",
            " 'pred_embed_dim': 128,\n",
            " 'pred_hidden_dim': 256,\n",
            " 'pred_model': 'rnn',\n",
            " 'ratio': '70',\n",
            " 'rnn_layer': 1,\n",
            " 'save_dir': 'checkpoints',\n",
            " 'save_prefix': 'checkpoint',\n",
            " 'seed': 1,\n",
            " 'src_data': 'eicu',\n",
            " 'task': 'readmission',\n",
            " 'transfer': False,\n",
            " 'valid_subsets': ['valid', 'test'],\n",
            " 'value_mode': 'VA'}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "[2024-05-08 01:28:06,133][trainers.trainer][INFO] - EHRModel(\n",
            "  (embed_model): BertTextEncoder(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 128)\n",
            "        (token_type_embeddings): Embedding(2, 128)\n",
            "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0-1): 2 x BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
            "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
            "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
            "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
            "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (post_encode_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (pred_model): RNNModel(\n",
            "    (model): GRU(128, 256, batch_first=True, dropout=0.3)\n",
            "    (final_proj): Linear(in_features=256, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "[2024-05-08 01:28:06,134][trainers.trainer][INFO] - task: readmission\n",
            "[2024-05-08 01:28:06,134][trainers.trainer][INFO] - model: EHRModel\n",
            "[2024-05-08 01:28:06,135][trainers.trainer][INFO] - num. model params: 4,699,137 (num. trained: 4,699,137)\n",
            "[2024-05-08 01:28:07,401][datasets.dataset][INFO] - loaded 13 train samples\n",
            "[2024-05-08 01:28:08,507][datasets.dataset][INFO] - loaded 4 valid samples\n",
            "[2024-05-08 01:28:09,796][datasets.dataset][INFO] - loaded 16 test samples\n",
            "[2024-05-08 01:28:10,863][trainers.trainer][INFO] - begin training epoch 1\n",
            "100% 1/1 [00:01<00:00,  1.38s/it]\n",
            "[2024-05-08 01:28:12,249][train][INFO] - epoch: 1, loss: 0.715, auroc: 0.750, auprc: 0.250\n",
            "[2024-05-08 01:28:12,250][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:28:12,279][valid][INFO] - epoch: 1, loss: 0.688, auroc: 0.333, auprc: 0.333\n",
            "[2024-05-08 01:28:12,279][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:28:12,343][test][INFO] - epoch: 1, loss: 1.368, auroc: 0.278, auprc: 0.103\n",
            "[2024-05-08 01:28:12,343][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:28:12,447][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:28:12,447][trainers.trainer][INFO] - begin training epoch 2\n",
            "100% 1/1 [00:00<00:00,  8.51it/s]\n",
            "[2024-05-08 01:28:12,567][train][INFO] - epoch: 2, loss: 0.676, auroc: 1.000, auprc: 1.000\n",
            "[2024-05-08 01:28:12,568][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:28:12,588][valid][INFO] - epoch: 2, loss: 0.689, auroc: 0.333, auprc: 0.333\n",
            "[2024-05-08 01:28:12,588][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:28:12,643][test][INFO] - epoch: 2, loss: 1.335, auroc: 0.389, auprc: 0.117\n",
            "[2024-05-08 01:28:12,643][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:28:12,800][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:28:12,800][trainers.trainer][INFO] - begin training epoch 3\n",
            "100% 1/1 [00:00<00:00,  9.14it/s]\n",
            "[2024-05-08 01:28:12,913][train][INFO] - epoch: 3, loss: 0.654, auroc: 0.167, auprc: 0.091\n",
            "[2024-05-08 01:28:12,914][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:28:12,933][valid][INFO] - epoch: 3, loss: 0.693, auroc: 0.333, auprc: 0.333\n",
            "[2024-05-08 01:28:12,933][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:28:12,981][test][INFO] - epoch: 3, loss: 1.308, auroc: 0.389, auprc: 0.117\n",
            "[2024-05-08 01:28:12,981][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:28:13,137][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:28:13,137][trainers.trainer][INFO] - begin training epoch 4\n",
            "100% 1/1 [00:00<00:00,  9.34it/s]\n",
            "[2024-05-08 01:28:13,247][train][INFO] - epoch: 4, loss: 0.620, auroc: 0.250, auprc: 0.100\n",
            "[2024-05-08 01:28:13,248][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:28:13,266][valid][INFO] - epoch: 4, loss: 0.698, auroc: 0.333, auprc: 0.333\n",
            "[2024-05-08 01:28:13,266][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:28:13,314][test][INFO] - epoch: 4, loss: 1.285, auroc: 0.361, auprc: 0.113\n",
            "[2024-05-08 01:28:13,314][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:28:13,451][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:28:13,451][trainers.trainer][INFO] - begin training epoch 5\n",
            "100% 1/1 [00:00<00:00,  9.55it/s]\n",
            "[2024-05-08 01:28:13,559][train][INFO] - epoch: 5, loss: 0.600, auroc: 0.000, auprc: 0.077\n",
            "[2024-05-08 01:28:13,560][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:28:13,579][valid][INFO] - epoch: 5, loss: 0.706, auroc: 0.333, auprc: 0.333\n",
            "[2024-05-08 01:28:13,579][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:28:13,630][test][INFO] - epoch: 5, loss: 1.267, auroc: 0.361, auprc: 0.113\n",
            "[2024-05-08 01:28:13,630][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:28:13,781][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:28:13,781][trainers.trainer][INFO] - begin training epoch 6\n",
            "100% 1/1 [00:00<00:00,  9.69it/s]\n",
            "[2024-05-08 01:28:13,887][train][INFO] - epoch: 6, loss: 0.578, auroc: 0.000, auprc: 0.077\n",
            "[2024-05-08 01:28:13,888][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:28:13,907][valid][INFO] - epoch: 6, loss: 0.715, auroc: 0.333, auprc: 0.333\n",
            "[2024-05-08 01:28:13,907][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:28:13,957][test][INFO] - epoch: 6, loss: 1.254, auroc: 0.361, auprc: 0.113\n",
            "[2024-05-08 01:28:13,957][utils.trainer_utils][INFO] - early stop since valid performance hasn't improved for last 5 runs\n",
            "[2024-05-08 01:28:13,957][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:28:14,842][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:28:14,844][__main__][INFO] - done training\n"
          ]
        }
      ],
      "source": [
        "# Example training new DescEmb model:\n",
        "# train_new_descemb_model('data_output_path/mimic', 'mimic', 'readmission', 100, 'DSVA')\n",
        "# train_new_descemb_model('data_output_path/eicu', 'eicu', 'mortality', 70, 'VA')\n",
        "\n",
        "!python main.py \\\n",
        "    --distributed_world_size 1 \\\n",
        "    --input_path '/content/cs598_descemb_project/datasets/data_output_path' \\\n",
        "    --model 'ehr_model' \\\n",
        "    --embed_model 'descemb_bert' \\\n",
        "    --pred_model 'rnn' \\\n",
        "    --src_data 'eicu' \\\n",
        "    --ratio 70 \\\n",
        "    --value_mode VA \\\n",
        "    --task 'readmission'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca4e6074-dba5-4ea6-ab17-2242a4233e13",
      "metadata": {
        "id": "ca4e6074-dba5-4ea6-ab17-2242a4233e13"
      },
      "source": [
        "**Note**: if you want to train with pre-trained BERT model, add command line parameters `--init_bert_params` or `--init_bert_params_with_freeze`. `--init_bert_params_with_freeze` enables the model to load and freeze BERT parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16384f0e-3812-4117-aea5-df6f7447e016",
      "metadata": {
        "id": "16384f0e-3812-4117-aea5-df6f7447e016"
      },
      "source": [
        "#### Fine-tune a Pre-Trained Model\n",
        "\n",
        "##### Fine-tuning a Pre-trained CodeEmb Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "ff972cd9-10d7-4544-9c5e-75da8583172d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff972cd9-10d7-4544-9c5e-75da8583172d",
        "outputId": "47172e82-40aa-49cb-a28f-bc979f4989ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-05-08 01:33:26 | INFO numexpr.utils NumExpr defaulting to 2 threads.)))\n",
            "[2024-05-08 01:33:27,764][trainers.trainer][INFO] - {'batch_size': 128,\n",
            " 'bert_model': 'bert_tiny',\n",
            " 'device_ids': [0],\n",
            " 'disable_validation': False,\n",
            " 'distributed_world_size': 1,\n",
            " 'dropout': 0.3,\n",
            " 'embed_model': 'codeemb',\n",
            " 'enc_embed_dim': 128,\n",
            " 'enc_hidden_dim': 256,\n",
            " 'eval_data': None,\n",
            " 'fold': None,\n",
            " 'init_bert_params': False,\n",
            " 'init_bert_params_with_freeze': False,\n",
            " 'input_path': '/content/cs598_descemb_project/datasets/data_output_path',\n",
            " 'load_pretrained_weights': False,\n",
            " 'lr': 0.0001,\n",
            " 'max_event_len': 150,\n",
            " 'mlm_prob': 0.3,\n",
            " 'model': 'ehr_model',\n",
            " 'model_path': '/content/cs598_descemb_project/outputs/2024-05-08/10-17-06/checkpoints/checkpoint_best.pt',\n",
            " 'n_epochs': 1000,\n",
            " 'patience': 5,\n",
            " 'pred_embed_dim': 128,\n",
            " 'pred_hidden_dim': 256,\n",
            " 'pred_model': 'rnn',\n",
            " 'ratio': '70',\n",
            " 'rnn_layer': 1,\n",
            " 'save_dir': 'checkpoints',\n",
            " 'save_prefix': 'checkpoint',\n",
            " 'seed': 1,\n",
            " 'src_data': 'eicu',\n",
            " 'task': 'readmission',\n",
            " 'transfer': False,\n",
            " 'valid_subsets': ['valid', 'test'],\n",
            " 'value_mode': 'DSVA'}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "[2024-05-08 01:33:27,777][trainers.trainer][INFO] - EHRModel(\n",
            "  (embed_model): CodeEmb(\n",
            "    (embedding): Embedding(5054, 128, padding_idx=0)\n",
            "  )\n",
            "  (pred_model): RNNModel(\n",
            "    (model): GRU(128, 256, batch_first=True, dropout=0.3)\n",
            "    (final_proj): Linear(in_features=256, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "[2024-05-08 01:33:27,778][trainers.trainer][INFO] - task: readmission\n",
            "[2024-05-08 01:33:27,778][trainers.trainer][INFO] - model: EHRModel\n",
            "[2024-05-08 01:33:27,778][trainers.trainer][INFO] - num. model params: 943,617 (num. trained: 943,617)\n",
            "[2024-05-08 01:33:29,135][datasets.dataset][INFO] - loaded 13 train samples\n",
            "[2024-05-08 01:33:30,208][datasets.dataset][INFO] - loaded 4 valid samples\n",
            "[2024-05-08 01:33:31,330][datasets.dataset][INFO] - loaded 16 test samples\n",
            "[2024-05-08 01:33:32,180][trainers.trainer][INFO] - begin training epoch 1\n",
            "100% 1/1 [00:00<00:00,  1.28it/s]\n",
            "[2024-05-08 01:33:32,963][train][INFO] - epoch: 1, loss: 0.635, auroc: 0.417, auprc: 0.125\n",
            "[2024-05-08 01:33:32,963][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:33:32,974][valid][INFO] - epoch: 1, loss: 0.707, auroc: 0.000, auprc: 0.250\n",
            "[2024-05-08 01:33:32,974][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:33:32,985][test][INFO] - epoch: 1, loss: 1.339, auroc: 0.306, auprc: 0.104\n",
            "[2024-05-08 01:33:32,985][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:33:33,007][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:33:33,007][trainers.trainer][INFO] - begin training epoch 2\n",
            "100% 1/1 [00:00<00:00, 58.63it/s]\n",
            "[2024-05-08 01:33:33,027][train][INFO] - epoch: 2, loss: 0.620, auroc: 0.417, auprc: 0.125\n",
            "[2024-05-08 01:33:33,027][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:33:33,037][valid][INFO] - epoch: 2, loss: 0.706, auroc: 0.000, auprc: 0.250\n",
            "[2024-05-08 01:33:33,037][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:33:33,048][test][INFO] - epoch: 2, loss: 1.328, auroc: 0.306, auprc: 0.104\n",
            "[2024-05-08 01:33:33,048][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:33:33,074][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:33:33,075][trainers.trainer][INFO] - begin training epoch 3\n",
            "100% 1/1 [00:00<00:00, 56.64it/s]\n",
            "[2024-05-08 01:33:33,095][train][INFO] - epoch: 3, loss: 0.607, auroc: 0.417, auprc: 0.125\n",
            "[2024-05-08 01:33:33,095][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:33:33,106][valid][INFO] - epoch: 3, loss: 0.706, auroc: 0.000, auprc: 0.250\n",
            "[2024-05-08 01:33:33,106][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:33:33,118][test][INFO] - epoch: 3, loss: 1.319, auroc: 0.306, auprc: 0.104\n",
            "[2024-05-08 01:33:33,118][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:33:33,155][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:33:33,155][trainers.trainer][INFO] - begin training epoch 4\n",
            "100% 1/1 [00:00<00:00, 58.66it/s]\n",
            "[2024-05-08 01:33:33,175][train][INFO] - epoch: 4, loss: 0.595, auroc: 0.417, auprc: 0.125\n",
            "[2024-05-08 01:33:33,175][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:33:33,185][valid][INFO] - epoch: 4, loss: 0.705, auroc: 0.000, auprc: 0.250\n",
            "[2024-05-08 01:33:33,185][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:33:33,195][test][INFO] - epoch: 4, loss: 1.310, auroc: 0.306, auprc: 0.104\n",
            "[2024-05-08 01:33:33,196][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:33:33,215][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:33:33,215][trainers.trainer][INFO] - begin training epoch 5\n",
            "100% 1/1 [00:00<00:00, 50.07it/s]\n",
            "[2024-05-08 01:33:33,238][train][INFO] - epoch: 5, loss: 0.584, auroc: 0.417, auprc: 0.125\n",
            "[2024-05-08 01:33:33,238][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:33:33,248][valid][INFO] - epoch: 5, loss: 0.705, auroc: 0.000, auprc: 0.250\n",
            "[2024-05-08 01:33:33,248][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:33:33,259][test][INFO] - epoch: 5, loss: 1.302, auroc: 0.306, auprc: 0.104\n",
            "[2024-05-08 01:33:33,259][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:33:33,279][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:33:33,279][trainers.trainer][INFO] - begin training epoch 6\n",
            "100% 1/1 [00:00<00:00, 52.69it/s]\n",
            "[2024-05-08 01:33:33,301][train][INFO] - epoch: 6, loss: 0.574, auroc: 0.417, auprc: 0.125\n",
            "[2024-05-08 01:33:33,301][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:33:33,311][valid][INFO] - epoch: 6, loss: 0.705, auroc: 0.000, auprc: 0.250\n",
            "[2024-05-08 01:33:33,311][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:33:33,321][test][INFO] - epoch: 6, loss: 1.295, auroc: 0.306, auprc: 0.104\n",
            "[2024-05-08 01:33:33,321][utils.trainer_utils][INFO] - early stop since valid performance hasn't improved for last 5 runs\n",
            "[2024-05-08 01:33:33,322][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:33:33,342][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:33:33,342][__main__][INFO] - done training\n"
          ]
        }
      ],
      "source": [
        "!python main.py \\\n",
        "    --distributed_world_size 1 \\\n",
        "    --input_path '/content/cs598_descemb_project/datasets/data_output_path' \\\n",
        "    --model_path '/content/cs598_descemb_project/outputs/2024-05-08/10-17-06/checkpoints/checkpoint_best.pt' \\\n",
        "    --model ehr_model \\\n",
        "    --embed_model 'codeemb' \\\n",
        "    --pred_model 'rnn' \\\n",
        "    --src_data 'eicu' \\\n",
        "    --ratio 70 \\\n",
        "    --value_mode 'DSVA' \\\n",
        "    --task 'readmission'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d66773dd-b2f5-4f1d-98f4-befdb14fa9be",
      "metadata": {
        "id": "d66773dd-b2f5-4f1d-98f4-befdb14fa9be"
      },
      "source": [
        "##### Fine-tuning a Pre-trained DescEmb Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "0e0fb247-8100-47e3-ade9-b7b5749e4d2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e0fb247-8100-47e3-ade9-b7b5749e4d2e",
        "outputId": "11aa5a8c-03b2-43e5-b0fd-b5fe7339c9bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-05-08 01:35:03 | INFO numexpr.utils NumExpr defaulting to 2 threads.)))\n",
            "[2024-05-08 01:35:04,306][trainers.trainer][INFO] - {'batch_size': 128,\n",
            " 'bert_model': 'bert_tiny',\n",
            " 'device_ids': [0],\n",
            " 'disable_validation': False,\n",
            " 'distributed_world_size': 1,\n",
            " 'dropout': 0.3,\n",
            " 'embed_model': 'descemb_bert',\n",
            " 'enc_embed_dim': 128,\n",
            " 'enc_hidden_dim': 256,\n",
            " 'eval_data': None,\n",
            " 'fold': None,\n",
            " 'init_bert_params': False,\n",
            " 'init_bert_params_with_freeze': False,\n",
            " 'input_path': '/content/cs598_descemb_project/datasets/data_output_path',\n",
            " 'load_pretrained_weights': False,\n",
            " 'lr': 0.0001,\n",
            " 'max_event_len': 150,\n",
            " 'mlm_prob': 0.3,\n",
            " 'model': 'ehr_model',\n",
            " 'model_path': '/content/cs598_descemb_project/outputs/2024-05-08/10-28-05/checkpoints/checkpoint_best.pt',\n",
            " 'n_epochs': 1000,\n",
            " 'patience': 5,\n",
            " 'pred_embed_dim': 128,\n",
            " 'pred_hidden_dim': 256,\n",
            " 'pred_model': 'rnn',\n",
            " 'ratio': '70',\n",
            " 'rnn_layer': 1,\n",
            " 'save_dir': 'checkpoints',\n",
            " 'save_prefix': 'checkpoint',\n",
            " 'seed': 1,\n",
            " 'src_data': 'eicu',\n",
            " 'task': 'readmission',\n",
            " 'transfer': False,\n",
            " 'valid_subsets': ['valid', 'test'],\n",
            " 'value_mode': 'VA'}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "[2024-05-08 01:35:05,089][trainers.trainer][INFO] - EHRModel(\n",
            "  (embed_model): BertTextEncoder(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 128)\n",
            "        (token_type_embeddings): Embedding(2, 128)\n",
            "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0-1): 2 x BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
            "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
            "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
            "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
            "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (post_encode_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (pred_model): RNNModel(\n",
            "    (model): GRU(128, 256, batch_first=True, dropout=0.3)\n",
            "    (final_proj): Linear(in_features=256, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "[2024-05-08 01:35:05,091][trainers.trainer][INFO] - task: readmission\n",
            "[2024-05-08 01:35:05,091][trainers.trainer][INFO] - model: EHRModel\n",
            "[2024-05-08 01:35:05,091][trainers.trainer][INFO] - num. model params: 4,699,137 (num. trained: 4,699,137)\n",
            "[2024-05-08 01:35:07,000][datasets.dataset][INFO] - loaded 13 train samples\n",
            "[2024-05-08 01:35:08,066][datasets.dataset][INFO] - loaded 4 valid samples\n",
            "[2024-05-08 01:35:09,210][datasets.dataset][INFO] - loaded 16 test samples\n",
            "[2024-05-08 01:35:09,878][trainers.trainer][INFO] - begin training epoch 1\n",
            "100% 1/1 [00:00<00:00,  1.01it/s]\n",
            "[2024-05-08 01:35:10,877][train][INFO] - epoch: 1, loss: 0.712, auroc: 0.250, auprc: 0.100\n",
            "[2024-05-08 01:35:10,877][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:35:10,904][valid][INFO] - epoch: 1, loss: 0.705, auroc: 0.333, auprc: 0.333\n",
            "[2024-05-08 01:35:10,904][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:35:10,974][test][INFO] - epoch: 1, loss: 1.375, auroc: 0.472, auprc: 0.133\n",
            "[2024-05-08 01:35:10,975][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:35:11,086][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:35:11,086][trainers.trainer][INFO] - begin training epoch 2\n",
            "100% 1/1 [00:00<00:00,  7.23it/s]\n",
            "[2024-05-08 01:35:11,227][train][INFO] - epoch: 2, loss: 0.670, auroc: 0.333, auprc: 0.111\n",
            "[2024-05-08 01:35:11,227][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:35:11,252][valid][INFO] - epoch: 2, loss: 0.708, auroc: 0.333, auprc: 0.333\n",
            "[2024-05-08 01:35:11,252][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:35:11,310][test][INFO] - epoch: 2, loss: 1.343, auroc: 0.472, auprc: 0.133\n",
            "[2024-05-08 01:35:11,310][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:35:11,459][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:35:11,459][trainers.trainer][INFO] - begin training epoch 3\n",
            "100% 1/1 [00:00<00:00,  9.53it/s]\n",
            "[2024-05-08 01:35:11,568][train][INFO] - epoch: 3, loss: 0.642, auroc: 0.250, auprc: 0.100\n",
            "[2024-05-08 01:35:11,568][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:35:11,587][valid][INFO] - epoch: 3, loss: 0.714, auroc: 0.333, auprc: 0.333\n",
            "[2024-05-08 01:35:11,587][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:35:11,634][test][INFO] - epoch: 3, loss: 1.317, auroc: 0.472, auprc: 0.133\n",
            "[2024-05-08 01:35:11,634][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:35:11,787][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:35:11,788][trainers.trainer][INFO] - begin training epoch 4\n",
            "100% 1/1 [00:00<00:00,  9.65it/s]\n",
            "[2024-05-08 01:35:11,894][train][INFO] - epoch: 4, loss: 0.615, auroc: 0.167, auprc: 0.091\n",
            "[2024-05-08 01:35:11,895][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:35:11,913][valid][INFO] - epoch: 4, loss: 0.721, auroc: 0.333, auprc: 0.333\n",
            "[2024-05-08 01:35:11,914][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:35:11,963][test][INFO] - epoch: 4, loss: 1.296, auroc: 0.500, auprc: 0.139\n",
            "[2024-05-08 01:35:11,964][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:35:12,065][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:35:12,065][trainers.trainer][INFO] - begin training epoch 5\n",
            "100% 1/1 [00:00<00:00,  8.98it/s]\n",
            "[2024-05-08 01:35:12,180][train][INFO] - epoch: 5, loss: 0.589, auroc: 0.250, auprc: 0.100\n",
            "[2024-05-08 01:35:12,180][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:35:12,199][valid][INFO] - epoch: 5, loss: 0.731, auroc: 0.333, auprc: 0.333\n",
            "[2024-05-08 01:35:12,199][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:35:12,247][test][INFO] - epoch: 5, loss: 1.281, auroc: 0.472, auprc: 0.133\n",
            "[2024-05-08 01:35:12,247][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:35:12,437][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:35:12,438][trainers.trainer][INFO] - begin training epoch 6\n",
            "100% 1/1 [00:00<00:00,  9.75it/s]\n",
            "[2024-05-08 01:35:12,543][train][INFO] - epoch: 6, loss: 0.563, auroc: 0.250, auprc: 0.100\n",
            "[2024-05-08 01:35:12,543][trainers.trainer][INFO] - begin validation on 'valid' subset\n",
            "[2024-05-08 01:35:12,561][valid][INFO] - epoch: 6, loss: 0.743, auroc: 0.333, auprc: 0.333\n",
            "[2024-05-08 01:35:12,562][trainers.trainer][INFO] - begin validation on 'test' subset\n",
            "[2024-05-08 01:35:12,609][test][INFO] - epoch: 6, loss: 1.271, auroc: 0.472, auprc: 0.133\n",
            "[2024-05-08 01:35:12,609][utils.trainer_utils][INFO] - early stop since valid performance hasn't improved for last 5 runs\n",
            "[2024-05-08 01:35:12,609][trainers.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:35:13,541][trainers.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt\n",
            "[2024-05-08 01:35:13,543][__main__][INFO] - done training\n"
          ]
        }
      ],
      "source": [
        "!python main.py \\\n",
        "    --distributed_world_size 1 \\\n",
        "    --input_path '/content/cs598_descemb_project/datasets/data_output_path' \\\n",
        "    --model_path '/content/cs598_descemb_project/outputs/2024-05-08/10-28-05/checkpoints/checkpoint_best.pt' \\\n",
        "    --model ehr_model \\\n",
        "    --embed_model 'descemb_bert' \\\n",
        "    --pred_model 'rnn' \\\n",
        "    --src_data 'eicu' \\\n",
        "    --ratio 70 \\\n",
        "    --value_mode VA \\\n",
        "    --task 'readmission'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "652e5d5d-b89b-4aff-a0e5-52d6e1cff492",
      "metadata": {
        "id": "652e5d5d-b89b-4aff-a0e5-52d6e1cff492"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "The primary metrics used in the `README.md` and the associated paper are **Area Under the Precision-Recall Curve (AUPRC)**.\n",
        "\n",
        "### Metrics Descriptions\n",
        "\n",
        "#### Area Under the Precision-Recall Curve (AUPRC):\n",
        "\n",
        "- **Precision (Positive Predictive Value)**: The ratio of true positive predictions to the total predicted positives. It shows the accuracy of the positive predictions.\n",
        "- **Recall (Sensitivity)**: The ratio of true positives to the actual total positives in the dataset. It measures the model's ability to capture positive instances.\n",
        "- **AUPRC**: The AUPRC is a single number summary of these two metrics across different thresholds, emphasizing the balance between precision and recall. It is especially valuable in medical predictions where the cost of false negatives is high.\n",
        "\n",
        "### Implementation Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "ea6a6394-9423-4704-924e-e5f5df531e27",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "ea6a6394-9423-4704-924e-e5f5df531e27",
        "outputId": "1a64d7e6-1cfe-449a-bbdb-e61444b06050"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'y_true' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-53ae04205056>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Example evaluation usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mauprc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_auprc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mplot_precision_recall_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calculate_auprc(y_true, y_scores):\n",
        "    \"\"\"\n",
        "    Calculate the Area Under the Precision-Recall Curve (AUPRC).\n",
        "\n",
        "    Args:\n",
        "    y_true (list or array): True binary labels in range {0, 1}.\n",
        "    y_scores (list or array): Target scores, can either be probability estimates of the positive class,\n",
        "                              confidence values, or non-thresholded measure of decisions.\n",
        "\n",
        "    Returns:\n",
        "    float: AUPRC score\n",
        "    \"\"\"\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
        "    auprc = auc(recall, precision)\n",
        "    return auprc\n",
        "\n",
        "def plot_precision_recall_curve(y_true, y_scores):\n",
        "    \"\"\"\n",
        "    Plot the Precision-Recall curve for a given set of true labels and scores.\n",
        "\n",
        "    Args:\n",
        "    y_true (list or array): True binary labels in range {0, 1}.\n",
        "    y_scores (list or array): Target scores, similar to calculate_auprc.\n",
        "    \"\"\"\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(recall, precision, label=f'AUPRC = {auc(recall, precision):.2f}')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall curve')\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "# Example evaluation usage\n",
        "auprc_score = calculate_auprc(y_true, y_scores)\n",
        "plot_precision_recall_curve(y_true, y_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5a2162a-9396-4a61-a4ac-667f70d0c824",
      "metadata": {
        "id": "a5a2162a-9396-4a61-a4ac-667f70d0c824"
      },
      "source": [
        "**Note**\n",
        "- Ensure that the `y_true` and `y_scores` are correctly formatted as arrays of true labels and model predictions respectively.\n",
        "- The plot_precision_recall_curve function provides a visual understanding of the trade-off between precision and recall for different threshold settings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fde43ed-cdbb-4c34-a9bc-4ac570073001",
      "metadata": {
        "id": "8fde43ed-cdbb-4c34-a9bc-4ac570073001"
      },
      "source": [
        "# Results\n",
        "\n",
        "## Results Overview\n",
        "\n",
        "The DescEmb models demonstrated superior or comparable performance to traditional code-based embeddings (CodeEmb) across various clinical prediction tasks. The models were evaluated on tasks such as predicting readmission, mortality, length of stay (both 3-day and 7-day), and diagnosis predictions using datasets like MIMIC-III and eICU.\n",
        "\n",
        "## Analyses\n",
        "\n",
        "- **Performance Gains**: DescEmb models, especially those leveraging BERT-based embeddings, showed consistent improvements in AUPRC (Area Under the Precision-Recall Curve) across most tasks compared to traditional models.\n",
        "- **Model Comparisons**: BERT-based DescEmb models generally outperformed simpler RNN-based models in complex tasks like diagnosis prediction, highlighting the effectiveness of pre-trained language models in handling complex textual data from EHRs.\n",
        "- **Impact of Pre-training**: The addition of Masked Language Modeling (MLM) pre-training marginally improved performance, suggesting that further domain-specific adaptation of language models could be beneficial.\n",
        "\n",
        "## Plans\n",
        "\n",
        "Moving forward, the research can focus on:\n",
        "- **Further Optimization**: Enhancing the efficiency of the models to make them accessible for real-time applications in clinical settings.\n",
        "- **Expanding Dataset Usage**: Applying the DescEmb framework to additional datasets and exploring its effectiveness across different healthcare systems.\n",
        "- **Advanced Model Architectures**: Investigating the integration of more complex neural architectures and their impact on the performance of EHR-based predictive models.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "The DescEmb approach marks a significant step forward in the use of NLP techniques for EHR data, offering a promising avenue for enhancing predictive healthcare analytics.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TPeSUSjp8EM_",
      "metadata": {
        "id": "TPeSUSjp8EM_"
      },
      "source": [
        "# Discussion of Reproducibility and Experimental Results\n",
        "\n",
        "## Implications of Experimental Results\n",
        "The attempt to reproduce the findings of the original paper highlighted several crucial aspects of the experimental setup and the limitations of available resources. Despite diligent efforts, the project did not achieve the same results as those documented, primarily due to constraints related to data handling and computational resources.\n",
        "\n",
        "##Reproducibility of the Original Paper\n",
        "The original paper, while comprehensive in many respects, presented significant challenges that hindered exact reproducibility:\n",
        "\n",
        "- **Data and Pretraining:** The datasets used were massive, which significantly prolonged the pretraining period. Even with access to enhanced computational resources through Google Colab Pro, the available resources fell short of the demands for processing such large datasets efficiently.\n",
        "- **Codebase Complexity:** The codebase provided by the original authors was extensive and complex. This complexity made it particularly challenging to navigate and implement the evaluation phase effectively.\n",
        "- **Documentation Gaps:** The documentation, especially around the evaluation methodology, lacked sufficient detail. This made it difficult to understand and replicate how the model’s performance was assessed, further complicating the reproduction process.\n",
        "\n",
        "\n",
        "## Challenges Encountered\n",
        "- **Resource Limitation:** The primary challenge was the sheer scale of data and the computational power required for pretraining. The resources available through Google Colab Pro, although substantial, were inadequate for handling the dataset efficiently.\n",
        "- **Technical Complexity:** Working through a vast and intricate codebase alone was particularly challenging. The complexity not only made it difficult to set up the project but also to reach the evaluation stage effectively.\n",
        "- **Isolated Working Environment:** Handling this project solo, especially given my busy schedule with work and family commitments, added an additional layer of difficulty. Collaboration could have alleviated some of the technical burdens and provided a platform for problem-solving and idea exchange.\n",
        "\n",
        "\n",
        "##Recommendations for Improving Reproducibility\n",
        "1. **Enhanced Documentation:** Future iterations of the work could benefit greatly from more detailed documentation, particularly concerning the evaluation methodology. Clear, step-by-step guidance could help replicate the results more effectively and efficiently.\n",
        "2. **Codebase Simplification:** Simplifying the codebase or at least organizing it with better modularity might help future researchers navigate the setup more easily.\n",
        "3. **Community Collaboration:** Encouraging collaboration by setting up a discussion forum or a community portal could help researchers and practitioners tackle common issues collectively. Collaboration could be particularly beneficial in pooling resources, sharing computational power, and exchanging practical insights.\n",
        "4. **Incremental Dataset Handling:** For projects involving massive datasets, it might be helpful to offer strategies or code alternatives for CPU testing to allow for incremental loading and processing of data. This could make the project more accessible to individuals or institutions with limited computational resources.\n",
        "\n",
        "By addressing these points, the original authors and others in the field can enhance the accessibility and reproducibility of their research, making it more feasible for a broader audience to engage with and build upon their work."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
